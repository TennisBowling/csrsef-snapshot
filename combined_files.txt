# Combined Files



# RST FILES FROM ./optuna/docs/



## File: source/_templates/autosummary/class.rst

{% extends "!autosummary/class.rst" %}

{#
An autosummary template to exclude the class constructor (__init__)
which doesn't contain any docstring in Optuna.
#}

{% block methods %}
   {% set methods = methods | select("ne", "__init__") | list %}
   {% if methods %}
   .. rubric:: Methods

   .. autosummary::
   {% for item in methods %}
      ~{{ name }}.{{ item }}
   {%- endfor %}
   {% endif %}

{% endblock %}


## File: source/faq.rst

FAQ
===

.. contents::
    :local:

Can I use Optuna with X? (where X is your favorite ML library)
--------------------------------------------------------------

Optuna is compatible with most ML libraries, and it's easy to use Optuna with those.
Please refer to `examples <https://github.com/optuna/optuna-examples/>`__.


.. _objective-func-additional-args:

How to define objective functions that have own arguments?
----------------------------------------------------------

There are two ways to realize it.

First, callable classes can be used for that purpose as follows:

.. code-block:: python

    import optuna


    class Objective:
        def __init__(self, min_x, max_x):
            # Hold this implementation specific arguments as the fields of the class.
            self.min_x = min_x
            self.max_x = max_x

        def __call__(self, trial):
            # Calculate an objective value by using the extra arguments.
            x = trial.suggest_float("x", self.min_x, self.max_x)
            return (x - 2) ** 2


    # Execute an optimization by using an `Objective` instance.
    study = optuna.create_study()
    study.optimize(Objective(-100, 100), n_trials=100)


Second, you can use ``lambda`` or ``functools.partial`` for creating functions (closures) that hold extra arguments.
Below is an example that uses ``lambda``:

.. code-block:: python

    import optuna

    # Objective function that takes three arguments.
    def objective(trial, min_x, max_x):
        x = trial.suggest_float("x", min_x, max_x)
        return (x - 2) ** 2


    # Extra arguments.
    min_x = -100
    max_x = 100

    # Execute an optimization by using the above objective function wrapped by `lambda`.
    study = optuna.create_study()
    study.optimize(lambda trial: objective(trial, min_x, max_x), n_trials=100)

Please also refer to `sklearn_additional_args.py <https://github.com/optuna/optuna-examples/tree/main/sklearn/sklearn_additional_args.py>`__ example,
which reuses the dataset instead of loading it in each trial execution.


Can I use Optuna without remote RDB servers?
--------------------------------------------

Yes, it's possible.

In the simplest form, Optuna works with :class:`~optuna.storages.InMemoryStorage`:

.. code-block:: python

    study = optuna.create_study()
    study.optimize(objective)


If you want to save and resume studies,  it's handy to use SQLite as the local storage:

.. code-block:: python

    study = optuna.create_study(study_name="foo_study", storage="sqlite:///example.db")
    study.optimize(objective)  # The state of `study` will be persisted to the local SQLite file.

Please see :ref:`rdb` for more details.


How can I save and resume studies?
----------------------------------------------------

There are two ways of persisting studies, which depend if you are using
:class:`~optuna.storages.InMemoryStorage` (default) or remote databases (RDB). In-memory studies can be
saved and loaded like usual Python objects using ``pickle`` or ``joblib``. For
example, using ``joblib``:

.. code-block:: python

    study = optuna.create_study()
    joblib.dump(study, "study.pkl")

And to resume the study:

.. code-block:: python

    study = joblib.load("study.pkl")
    print("Best trial until now:")
    print(" Value: ", study.best_trial.value)
    print(" Params: ")
    for key, value in study.best_trial.params.items():
        print(f"    {key}: {value}")

Note that Optuna does not support saving/reloading across different Optuna
versions with ``pickle``. To save/reload a study across different Optuna versions,
please use RDBs and `upgrade storage schema <reference/cli.html#storage-upgrade>`__
if necessary. If you are using RDBs, see :ref:`rdb` for more details.

How to suppress log messages of Optuna?
---------------------------------------

By default, Optuna shows log messages at the ``optuna.logging.INFO`` level.
You can change logging levels by using  :func:`optuna.logging.set_verbosity`.

For instance, you can stop showing each trial result as follows:

.. code-block:: python

    optuna.logging.set_verbosity(optuna.logging.WARNING)

    study = optuna.create_study()
    study.optimize(objective)
    # Logs like '[I 2020-07-21 13:41:45,627] Trial 0 finished with value:...' are disabled.


Please refer to :class:`optuna.logging` for further details.


How to save machine learning models trained in objective functions?
-------------------------------------------------------------------

Optuna saves hyperparameter values with their corresponding objective values to storage, 
but it discards intermediate objects such as machine learning models and neural network weights.

To save models or weights, we recommend utilizing Optuna's built-in ``ArtifactStore``.
For example, you can use the :func:`~optuna.artifacts.upload_artifact` as follows:

.. code-block:: python

    base_path = "./artifacts"
    os.makedirs(base_path, exist_ok=True)
    artifact_store = optuna.artifacts.FileSystemArtifactStore(base_path=base_path)
    
    def objective(trial):
        svc_c = trial.suggest_float("svc_c", 1e-10, 1e10, log=True)
        clf = sklearn.svm.SVC(C=svc_c)
        clf.fit(X_train, y_train)

        # Save the model using ArtifactStore
        with open("model.pickle", "wb") as fout:
            pickle.dump(clf, fout)
        artifact_id = optuna.artifacts.upload_artifact(
            artifact_store=artifact_store,
            file_path="model.pickle",
            study_or_trial=trial.study,
        )
        trial.set_user_attr("artifact_id", artifact_id)
        return 1.0 - accuracy_score(y_valid, clf.predict(X_valid))

    study = optuna.create_study()
    study.optimize(objective, n_trials=100)

To retrieve models or weights, you can list and download them using :func:`~optuna.artifacts.get_all_artifact_meta` and :func:`~optuna.artifacts.download_artifact` as shown below:

.. code-block:: python
    
    # List all models
    for artifact_meta in optuna.artifacts.get_all_artifact_meta(study_or_trial=study):
        print(artifact_meta)
    # Download the best model
    trial = study.best_trial
    best_artifact_id = trial.user_attrs["artifact_id"]
    optuna.artifacts.download_artifact(
        artifact_store=artifact_store,
        file_path='best_model.pickle',
        artifact_id=best_artifact_id,
    )

For a more comprehensive guide, refer to the `ArtifactStore tutorial <https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/012_artifact_tutorial.html>`_.

How can I obtain reproducible optimization results?
---------------------------------------------------

To make the parameters suggested by Optuna reproducible, you can specify a fixed random seed via ``seed`` argument of an instance of :mod:`~optuna.samplers` as follows:

.. code-block:: python

    sampler = TPESampler(seed=10)  # Make the sampler behave in a deterministic way.
    study = optuna.create_study(sampler=sampler)
    study.optimize(objective)

However, there are two caveats.

First, when optimizing a study in distributed or parallel mode, there is inherent non-determinism.
Thus it is very difficult to reproduce the same results in such condition.
We recommend executing optimization of a study sequentially if you would like to reproduce the result.

Second, if your objective function behaves in a non-deterministic way (i.e., it does not return the same value even if the same parameters were suggested), you cannot reproduce an optimization.
To deal with this problem, please set an option (e.g., random seed) to make the behavior deterministic if your optimization target (e.g., an ML library) provides it.


How are exceptions from trials handled?
---------------------------------------

Trials that raise exceptions without catching them will be treated as failures, i.e. with the :obj:`~optuna.trial.TrialState.FAIL` status.

By default, all exceptions except :class:`~optuna.exceptions.TrialPruned` raised in objective functions are propagated to the caller of :func:`~optuna.study.Study.optimize`.
In other words, studies are aborted when such exceptions are raised.
It might be desirable to continue a study with the remaining trials.
To do so, you can specify in :func:`~optuna.study.Study.optimize` which exception types to catch using the ``catch`` argument.
Exceptions of these types are caught inside the study and will not propagate further.

You can find the failed trials in log messages.

.. code-block:: sh

    [W 2018-12-07 16:38:36,889] Setting status of trial#0 as TrialState.FAIL because of \
    the following error: ValueError('A sample error in objective.')

You can also find the failed trials by checking the trial states as follows:

.. code-block:: python

    study.trials_dataframe()

.. csv-table::

    number,state,value,...,params,system_attrs
    0,TrialState.FAIL,,...,0,Setting status of trial#0 as TrialState.FAIL because of the following error: ValueError('A test error in objective.')
    1,TrialState.COMPLETE,1269,...,1,

.. seealso::

    The ``catch`` argument in :func:`~optuna.study.Study.optimize`.


How are NaNs returned by trials handled?
----------------------------------------

Trials that return NaN (``float('nan')``) are treated as failures, but they will not abort studies.

Trials which return NaN are shown as follows:

.. code-block:: sh

    [W 2018-12-07 16:41:59,000] Setting status of trial#2 as TrialState.FAIL because the \
    objective function returned nan.


What happens when I dynamically alter a search space?
-----------------------------------------------------

Since parameters search spaces are specified in each call to the suggestion API, e.g.
:func:`~optuna.trial.Trial.suggest_float` and :func:`~optuna.trial.Trial.suggest_int`,
it is possible to, in a single study, alter the range by sampling parameters from different search
spaces in different trials.
The behavior when altered is defined by each sampler individually.

.. note::

    Discussion about the TPE sampler. https://github.com/optuna/optuna/issues/822


How can I use two GPUs for evaluating two trials simultaneously?
----------------------------------------------------------------

If your optimization target supports GPU (CUDA) acceleration and you want to specify which GPU is used in your script,
``main.py``, the easiest way is to set ``CUDA_VISIBLE_DEVICES`` environment variable:

.. code-block:: bash

    # On a terminal.
    #
    # Specify to use the first GPU, and run an optimization.
    $ export CUDA_VISIBLE_DEVICES=0
    $ python main.py

    # On another terminal.
    #
    # Specify to use the second GPU, and run another optimization.
    $ export CUDA_VISIBLE_DEVICES=1
    $ python main.py

Please refer to `CUDA C Programming Guide <https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars>`__ for further details.


How can I test my objective functions?
--------------------------------------

When you test objective functions, you may prefer fixed parameter values to sampled ones.
In that case, you can use :class:`~optuna.trial.FixedTrial`, which suggests fixed parameter values based on a given dictionary of parameters.
For instance, you can input arbitrary values of :math:`x` and :math:`y` to the objective function :math:`x + y` as follows:

.. code-block:: python

    def objective(trial):
        x = trial.suggest_float("x", -1.0, 1.0)
        y = trial.suggest_int("y", -5, 5)
        return x + y


    objective(FixedTrial({"x": 1.0, "y": -1}))  # 0.0
    objective(FixedTrial({"x": -1.0, "y": -4}))  # -5.0


Using :class:`~optuna.trial.FixedTrial`, you can write unit tests as follows:

.. code-block:: python

    # A test function of pytest
    def test_objective():
        assert 1.0 == objective(FixedTrial({"x": 1.0, "y": 0}))
        assert -1.0 == objective(FixedTrial({"x": 0.0, "y": -1}))
        assert 0.0 == objective(FixedTrial({"x": -1.0, "y": 1}))


.. _out-of-memory-gc-collect:

How do I avoid running out of memory (OOM) when optimizing studies?
-------------------------------------------------------------------

If the memory footprint increases as you run more trials, try to periodically run the garbage collector.
Specify ``gc_after_trial`` to :obj:`True` when calling :func:`~optuna.study.Study.optimize` or call :func:`gc.collect` inside a callback.

.. code-block:: python

    def objective(trial):
        x = trial.suggest_float("x", -1.0, 1.0)
        y = trial.suggest_int("y", -5, 5)
        return x + y


    study = optuna.create_study()
    study.optimize(objective, n_trials=10, gc_after_trial=True)

    # `gc_after_trial=True` is more or less identical to the following.
    study.optimize(objective, n_trials=10, callbacks=[lambda study, trial: gc.collect()])

There is a performance trade-off for running the garbage collector, which could be non-negligible depending on how fast your objective function otherwise is. Therefore, ``gc_after_trial`` is :obj:`False` by default.
Note that the above examples are similar to running the garbage collector inside the objective function, except for the fact that :func:`gc.collect` is called even when errors, including :class:`~optuna.exceptions.TrialPruned` are raised.

.. note::

    :class:`~optuna.integration.ChainerMNStudy` does currently not provide ``gc_after_trial`` nor callbacks for :func:`~optuna.integration.ChainerMNStudy.optimize`.
    When using this class, you will have to call the garbage collector inside the objective function.

How can I output a log only when the best value is updated?
-----------------------------------------------------------

Here's how to replace the logging feature of optuna with your own logging callback function.
The implemented callback can be passed to :func:`~optuna.study.Study.optimize`.
Here's an example:

.. code-block:: python

    import optuna


    # Turn off optuna log notes.
    optuna.logging.set_verbosity(optuna.logging.WARN)


    def objective(trial):
        x = trial.suggest_float("x", 0, 1)
        return x ** 2


    def logging_callback(study, frozen_trial):
        previous_best_value = study.user_attrs.get("previous_best_value", None)
        if previous_best_value != study.best_value:
            study.set_user_attr("previous_best_value", study.best_value)
            print(
                "Trial {} finished with best value: {} and parameters: {}. ".format(
                frozen_trial.number,
                frozen_trial.value,
                frozen_trial.params,
                )
            )


    study = optuna.create_study()
    study.optimize(objective, n_trials=100, callbacks=[logging_callback])

Note that this callback may show incorrect values when you try to optimize an objective function with ``n_jobs!=1``
(or other forms of distributed optimization) due to its reads and writes to storage that are prone to race conditions.

How do I suggest variables which represent the proportion, that is, are in accordance with Dirichlet distribution?
------------------------------------------------------------------------------------------------------------------

When you want to suggest :math:`n` variables which represent the proportion, that is, :math:`p[0], p[1], ..., p[n-1]` which satisfy :math:`0 \le p[k] \le 1` for any :math:`k` and :math:`p[0] + p[1] + ... + p[n-1] = 1`, try the below.
For example, these variables can be used as weights when interpolating the loss functions.
These variables are in accordance with the flat `Dirichlet distribution <https://en.wikipedia.org/wiki/Dirichlet_distribution>`__.

.. code-block:: python

    import numpy as np
    import matplotlib.pyplot as plt
    import optuna


    def objective(trial):
        n = 5
        x = []
        for i in range(n):
            x.append(- np.log(trial.suggest_float(f"x_{i}", 0, 1)))

        p = []
        for i in range(n):
            p.append(x[i] / sum(x))

        for i in range(n):
            trial.set_user_attr(f"p_{i}", p[i])

        return 0

    study = optuna.create_study(sampler=optuna.samplers.RandomSampler())
    study.optimize(objective, n_trials=1000)

    n = 5
    p = []
    for i in range(n):
        p.append([trial.user_attrs[f"p_{i}"] for trial in study.trials])
    axes = plt.subplots(n, n, figsize=(20, 20))[1]

    for i in range(n):
        for j in range(n):
            axes[j][i].scatter(p[i], p[j], marker=".")
            axes[j][i].set_xlim(0, 1)
            axes[j][i].set_ylim(0, 1)
            axes[j][i].set_xlabel(f"p_{i}")
            axes[j][i].set_ylabel(f"p_{j}")

    plt.savefig("sampled_ps.png")

This method is justified in the following way:
First, if we apply the transformation :math:`x = - \log (u)` to the variable :math:`u` sampled from the uniform distribution :math:`Uni(0, 1)` in the interval :math:`[0, 1]`, the variable :math:`x` will follow the exponential distribution :math:`Exp(1)` with scale parameter :math:`1`.
Furthermore, for :math:`n` variables :math:`x[0], ..., x[n-1]` that follow the exponential distribution of scale parameter :math:`1` independently, normalizing them with :math:`p[i] = x[i] / \sum_i x[i]`, the vector :math:`p` follows the Dirichlet distribution :math:`Dir(\alpha)` of scale parameter :math:`\alpha = (1, ..., 1)`.
You can verify the transformation by calculating the elements of the Jacobian.

How can I optimize a model with some constraints?
-------------------------------------------------

When you want to optimize a model with constraints, you can use the following classes: :class:`~optuna.samplers.TPESampler`, :class:`~optuna.samplers.NSGAIISampler` or `BoTorchSampler <https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.BoTorchSampler.html>`__.
The following example is a benchmark of Binh and Korn function, a multi-objective optimization, with constraints using :class:`~optuna.samplers.NSGAIISampler`. This one has two constraints :math:`c_0 = (x-5)^2 + y^2 - 25 \le 0` and :math:`c_1 = -(x - 8)^2 - (y + 3)^2 + 7.7 \le 0` and finds the optimal solution satisfying these constraints.


.. code-block:: python

    import optuna


    def objective(trial):
        # Binh and Korn function with constraints.
        x = trial.suggest_float("x", -15, 30)
        y = trial.suggest_float("y", -15, 30)

        # Constraints which are considered feasible if less than or equal to zero.
        # The feasible region is basically the intersection of a circle centered at (x=5, y=0)
        # and the complement to a circle centered at (x=8, y=-3).
        c0 = (x - 5) ** 2 + y ** 2 - 25
        c1 = -((x - 8) ** 2) - (y + 3) ** 2 + 7.7

        # Store the constraints as user attributes so that they can be restored after optimization.
        trial.set_user_attr("constraint", (c0, c1))

        v0 = 4 * x ** 2 + 4 * y ** 2
        v1 = (x - 5) ** 2 + (y - 5) ** 2

        return v0, v1


    def constraints(trial):
        return trial.user_attrs["constraint"]


    sampler = optuna.samplers.NSGAIISampler(constraints_func=constraints)
    study = optuna.create_study(
        directions=["minimize", "minimize"],
        sampler=sampler,
    )
    study.optimize(objective, n_trials=32, timeout=600)

    print("Number of finished trials: ", len(study.trials))

    print("Pareto front:")

    trials = sorted(study.best_trials, key=lambda t: t.values)

    for trial in trials:
        print("  Trial#{}".format(trial.number))
        print(
            "    Values: Values={}, Constraint={}".format(
                trial.values, trial.user_attrs["constraint"][0]
            )
        )
        print("    Params: {}".format(trial.params))

If you are interested in an example for `BoTorchSampler <https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.BoTorchSampler.html>`__, please refer to `this sample code <https://github.com/optuna/optuna-examples/blob/main/multi_objective/botorch_simple.py>`__.


There are two kinds of constrained optimizations, one with soft constraints and the other with hard constraints.
Soft constraints do not have to be satisfied, but an objective function is penalized if they are unsatisfied. On the other hand, hard constraints must be satisfied.

Optuna is adopting the soft one and **DOES NOT** support the hard one. In other words, Optuna **DOES NOT** have built-in samplers for the hard constraints.

How can I parallelize optimization?
-----------------------------------

The variations of parallelization are in the following three cases.

1. Multi-threading parallelization with single node
2. Multi-processing parallelization with single node
3. Multi-processing parallelization with multiple nodes

1. Multi-threading parallelization with a single node
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Parallelization can be achieved by setting the argument ``n_jobs`` in :func:`optuna.study.Study.optimize`.
However, the python code will not be faster due to GIL because :func:`optuna.study.Study.optimize` with ``n_jobs!=1`` uses multi-threading.

While optimizing, it will be faster in limited situations, such as waiting for other server requests or C/C++ processing with numpy, etc., but it will not be faster in other cases.

For more information about 1., see APIReference_.

.. _APIReference: https://optuna.readthedocs.io/en/stable/reference/index.html

2. Multi-processing parallelization with single node
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This can be achieved by using :class:`~optuna.storages.journal.JournalFileBackend` or client/server RDBs (such as PostgreSQL and MySQL).

For more information about 2., see TutorialEasyParallelization_.

.. _TutorialEasyParallelization: https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html

3. Multi-processing parallelization with multiple nodes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This can be achieved by using client/server RDBs (such as PostgreSQL and MySQL).
However, if you are in the environment where you can not install a client/server RDB, you can not run multi-processing parallelization with multiple nodes.

For more information about 3., see TutorialEasyParallelization_.

.. _sqlite_concurrency:

How can I solve the error that occurs when performing parallel optimization with SQLite3?
-----------------------------------------------------------------------------------------

We would never recommend SQLite3 for parallel optimization in the following reasons.

- To concurrently evaluate trials enqueued by :func:`~optuna.study.Study.enqueue_trial`, :class:`~optuna.storages.RDBStorage` uses `SELECT ... FOR UPDATE` syntax, which is unsupported in `SQLite3 <https://github.com/sqlalchemy/sqlalchemy/blob/rel_1_4_41/lib/sqlalchemy/dialects/sqlite/base.py#L1265-L1267>`__.
- As described in `the SQLAlchemy's documentation <https://docs.sqlalchemy.org/en/14/dialects/sqlite.html#sqlite-concurrency>`__,
  SQLite3 (and pysqlite driver) does not support a high level of concurrency.
  You may get a "database is locked" error, which occurs when one thread or process has an exclusive lock on a database connection (in reality a file handle) and another thread times out waiting for the lock to be released.
  You can increase the default `timeout <https://docs.python.org/3/library/sqlite3.html#sqlite3.connect>`__ value like `optuna.storages.RDBStorage("sqlite:///example.db", engine_kwargs={"connect_args": {"timeout": 20.0}})` though.
- For distributed optimization via NFS, SQLite3 does not work as described at `FAQ section of sqlite.org <https://www.sqlite.org/faq.html#q5>`__.

If you want to use a file-based Optuna storage for these scenarios, please consider using :class:`~optuna.storages.journal.JournalFileBackend` instead.

.. code-block:: python

   import optuna
   from optuna.storages import JournalStorage
   from optuna.storages.journal import JournalFileBackend

   storage = JournalStorage(JournalFileBackend("optuna_journal_storage.log"))

   study = optuna.create_study(storage=storage)
   ...

See `the Medium blog post <https://medium.com/optuna/distributed-optimization-via-nfs-using-optunas-new-operation-based-logging-storage-9815f9c3f932>`__ for details.

.. _heartbeat_monitoring:

Can I monitor trials and make them failed automatically when they are killed unexpectedly?
------------------------------------------------------------------------------------------

.. note::

  Heartbeat mechanism is experimental. API would change in the future.

A process running a trial could be killed unexpectedly, typically by a job scheduler in a cluster environment.
If trials are killed unexpectedly, they will be left on the storage with their states `RUNNING` until we remove them or update their state manually.
For such a case, Optuna supports monitoring trials using `heartbeat <https://en.wikipedia.org/wiki/Heartbeat_(computing)>`__ mechanism.
Using heartbeat, if a process running a trial is killed unexpectedly,
Optuna will automatically change the state of the trial that was running on that process to :obj:`~optuna.trial.TrialState.FAIL`
from :obj:`~optuna.trial.TrialState.RUNNING`.

.. code-block:: python

    import optuna

    def objective(trial):
        (Very time-consuming computation)

    # Recording heartbeats every 60 seconds.
    # Other processes' trials where more than 120 seconds have passed
    # since the last heartbeat was recorded will be automatically failed.
    storage = optuna.storages.RDBStorage(url="sqlite:///:memory:", heartbeat_interval=60, grace_period=120)
    study = optuna.create_study(storage=storage)
    study.optimize(objective, n_trials=100)

.. note::

  The heartbeat is supposed to be used with :meth:`~optuna.study.Study.optimize`. If you use :meth:`~optuna.study.Study.ask` and
  :meth:`~optuna.study.Study.tell`, please change the state of the killed trials by calling :meth:`~optuna.study.Study.tell`
  explicitly.

You can also execute a callback function to process the failed trial.
Optuna provides a callback to retry failed trials as :class:`~optuna.storages.RetryFailedTrialCallback`.
Note that a callback is invoked at a beginning of each trial, which means :class:`~optuna.storages.RetryFailedTrialCallback`
will retry failed trials when a new trial starts to evaluate.

.. code-block:: python

    import optuna
    from optuna.storages import RetryFailedTrialCallback

    storage = optuna.storages.RDBStorage(
        url="sqlite:///:memory:",
        heartbeat_interval=60,
        grace_period=120,
        failed_trial_callback=RetryFailedTrialCallback(max_retry=3),
    )

    study = optuna.create_study(storage=storage)


How can I deal with permutation as a parameter?
-----------------------------------------------

Although it is not straightforward to deal with combinatorial search spaces like permutations with existing API, there exists a convenient technique for handling them.
It involves re-parametrization of permutation search space of :math:`n` items as an independent :math:`n`-dimensional integer search space.
This technique is based on the concept of `Lehmer code <https://en.wikipedia.org/wiki/Lehmer_code>`__.

A Lehmer code of a sequence is the sequence of integers in the same size, whose :math:`i`-th entry denotes how many inversions the :math:`i`-th entry of the permutation has after itself.
In other words, the :math:`i`-th entry of the Lehmer code represents the number of entries that are located after and are smaller than the :math:`i`-th entry of the original sequence.
For instance, the Lehmer code of the permutation :math:`(3, 1, 4, 2, 0)` is :math:`(3, 1, 2, 1, 0)`.

Not only does the Lehmer code provide a unique encoding of permutations into an integer space, but it also has some desirable properties.
For example, the sum of Lehmer code entries is equal to the minimum number of adjacent transpositions necessary to transform the corresponding permutation into the identity permutation.
Additionally, the lexicographical order of the encodings of two permutations is the same as that of the original sequence.
Therefore, Lehmer code preserves "closeness" among permutations in some sense, which is important for the optimization algorithm.
An Optuna implementation example to solve Euclid TSP is as follows:

.. code-block:: python

    import numpy as np

    import optuna


    def decode(lehmer_code: list[int]) -> list[int]:
        """Decode Lehmer code to permutation.

        This function decodes Lehmer code represented as a list of integers to a permutation.
        """
        all_indices = list(range(n))
        output = []
        for k in lehmer_code:
            value = all_indices[k]
            output.append(value)
            all_indices.remove(value)
        return output


    # Euclidean coordinates of cities for TSP.
    city_coordinates = np.array(
        [[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0], [2.0, 2.0], [-1.0, -1.0]]
    )
    n = len(city_coordinates)


    def objective(trial: optuna.Trial) -> float:
        # Suggest a permutation in the Lehmer code representation.
        lehmer_code = [trial.suggest_int(f"x{i}", 0, n - i - 1) for i in range(n)]
        permutation = decode(lehmer_code)

        # Calculate the total distance of the suggested path.
        total_distance = 0.0
        for i in range(n):
            total_distance += np.linalg.norm(
                city_coordinates[permutation[i]] - city_coordinates[np.roll(permutation, 1)[i]]
            )
        return total_distance


    study = optuna.create_study()
    study.optimize(objective, n_trials=10)
    lehmer_code = study.best_params.values()
    print(decode(lehmer_code))

How can I ignore duplicated samples?
------------------------------------

Optuna may sometimes suggest parameters evaluated in the past and if you would like to avoid this problem, you can try out the following workaround:

.. code-block:: python

    import optuna
    from optuna.trial import TrialState


    def objective(trial):
        # Sample parameters.
        x = trial.suggest_int("x", -5, 5)
        y = trial.suggest_int("y", -5, 5)
        # Fetch all the trials to consider.
        # In this example, we use only completed trials, but users can specify other states
        # such as TrialState.PRUNED and TrialState.FAIL.
        states_to_consider = (TrialState.COMPLETE,)
        trials_to_consider = trial.study.get_trials(deepcopy=False, states=states_to_consider)
        # Check whether we already evaluated the sampled `(x, y)`.
        for t in reversed(trials_to_consider):
            if trial.params == t.params:
                # Use the existing value as trial duplicated the parameters.
                return t.value

        # Compute the objective function if the parameters are not duplicated.
        # We use the 2D sphere function in this example.
        return x ** 2 + y ** 2


    study = optuna.create_study()
    study.optimize(objective, n_trials=100)

.. _remove_for_artifact_store:

How can I delete all the artifacts uploaded to a study?
-------------------------------------------------------

Optuna supports :mod:`~optuna.artifacts` for large data storage during an optimization.
After you conduct enormous amount of experiments, you may want to remove the artifacts stored during optimizations.

We strongly recommend to create a new directory or bucket for each study so that all the artifacts linked to a study can be entirely removed by deleting the directory or the bucket.

However, if it is necessary to remove artifacts from a Python script, users can use the following code:

.. warning::

    :func:`~optuna.study.Study.add_trial` and :meth:`~optuna.study.copy_study` do not copy artifact files linked to :class:`~optuna.study.Study` or :class:`~optuna.trial.Trial`.
    Please make sure **NOT** to delete the artifacts from the source study or trial.
    Failing to do so may lead to unexpected behaviors as Optuna does not guarantee expected behaviors when users call :meth:`remove` externally.
    Due to the Optuna software design, it is hard to officially support the delete feature and we are not planning to support this feature in the future either. 

.. code-block:: python

    from optuna.artifacts import get_all_artifact_meta


    def remove_artifacts(study, artifact_store):
        # NOTE: ``artifact_store.remove`` is discouraged to use because it is an internal feature.
        storage = study._storage
        for trial in study.trials:
            for artifact_meta in get_all_artifact_meta(trial, storage=storage):
                # For each trial, remove the artifacts uploaded to ``base_path``.
                artifact_store.remove(artifact_meta.artifact_id)

        for artifact_meta in get_all_artifact_meta(study):
            # Remove the artifacts uploaded to ``base_path``.
            artifact_store.remove(artifact_meta.artifact_id)


## File: source/index.rst

|optunalogo|

Optuna: A hyperparameter optimization framework
===============================================

*Optuna* is an automatic hyperparameter optimization software framework,
particularly designed for machine learning. It features an imperative,
*define-by-run* style user API. Thanks to our *define-by-run* API, the
code written with Optuna enjoys high modularity, and the user of Optuna
can dynamically construct the search spaces for the hyperparameters.

Key Features
------------

Optuna has modern functionalities as follows:

- :doc:`Lightweight, versatile, and platform agnostic architecture <tutorial/10_key_features/001_first>`

  - Handle a wide variety of tasks with a simple installation that has few requirements.

- :doc:`Pythonic search spaces <tutorial/10_key_features/002_configurations>`

  - Define search spaces using familiar Python syntax including conditionals and loops.

- :doc:`Efficient optimization algorithms <tutorial/10_key_features/003_efficient_optimization_algorithms>`

  - Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.

- :doc:`Easy parallelization <tutorial/10_key_features/004_distributed>`

  - Scale studies to tens or hundreds of workers with little or no changes to the code.

- :doc:`Quick visualization <tutorial/10_key_features/005_visualization>`

  - Inspect optimization histories from a variety of plotting functions.

Basic Concepts
--------------

We use the terms *study* and *trial* as follows:

-  Study: optimization based on an objective function
-  Trial: a single execution of the objective function

Please refer to sample code below. The goal of a *study* is to find out
the optimal set of hyperparameter values (e.g., ``classifier`` and
``svm_c``) through multiple *trials* (e.g., ``n_trials=100``). Optuna is
a framework designed for the automation and the acceleration of the
optimization *studies*.

|Open in Colab|

.. code:: python

    import ...

    # Define an objective function to be minimized.
    def objective(trial):

        # Invoke suggest methods of a Trial object to generate hyperparameters.
        regressor_name = trial.suggest_categorical('classifier', ['SVR', 'RandomForest'])
        if regressor_name == 'SVR':
            svr_c = trial.suggest_float('svr_c', 1e-10, 1e10, log=True)
            regressor_obj = sklearn.svm.SVR(C=svr_c)
        else:
            rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)
            regressor_obj = sklearn.ensemble.RandomForestRegressor(max_depth=rf_max_depth)

        X, y = sklearn.datasets.fetch_california_housing(return_X_y=True)
        X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, random_state=0)

        regressor_obj.fit(X_train, y_train)
        y_pred = regressor_obj.predict(X_val)

        error = sklearn.metrics.mean_squared_error(y_val, y_pred)

        return error  # An objective value linked with the Trial object.

    study = optuna.create_study()  # Create a new study.
    study.optimize(objective, n_trials=100)  # Invoke optimization of the objective function.

Web Dashboard
-------------

`Optuna Dashboard <https://github.com/optuna/optuna-dashboard>`__ is a real-time web dashboard for Optuna.
You can check the optimization history, hyperparameter importance, etc. in graphs and tables.
You don't need to create a Python script to call `Optuna's visualization <https://optuna.readthedocs.io/en/stable/reference/visualization/index.html>`__ functions.
Feature requests and bug reports are welcome!

.. image:: https://user-images.githubusercontent.com/5564044/204975098-95c2cb8c-0fb5-4388-abc4-da32f56cb4e5.gif

``optuna-dashboard`` can be installed via pip:

.. code-block:: console

   $ pip install optuna-dashboard

.. TIP::

   Please check out the `getting started <https://optuna-dashboard.readthedocs.io/en/stable/getting-started.html>`__ section of Optuna Dashboard's official documentation.

Communication
-------------

-  `GitHub Discussions <https://github.com/optuna/optuna/discussions>`__ for questions.
-  `GitHub Issues <https://github.com/optuna/optuna/issues>`__ for bug
   reports and feature requests.

Contribution
------------

Any contributions to Optuna are welcome! When you send a pull request,
please follow the `contribution guide <https://github.com/optuna/optuna/blob/master/CONTRIBUTING.md>`__.

License
-------

MIT License (see `LICENSE <https://github.com/optuna/optuna/blob/master/LICENSE>`__).

Optuna uses the codes from SciPy and fdlibm projects (see :doc:`Third-party License <license_thirdparty>`).

Reference
---------

Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori
Koyama. 2019. Optuna: A Next-generation Hyperparameter Optimization
Framework. In KDD (`arXiv <https://arxiv.org/abs/1907.10902>`__).

.. toctree::
   :maxdepth: 2
   :caption: Contents:

   installation
   tutorial/index
   reference/index
   faq

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

.. |optunalogo| image:: https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png
  :width: 800
  :alt: OPTUNA
.. |Open in Colab| image:: https://colab.research.google.com/assets/colab-badge.svg
  :target: http://colab.research.google.com/github/optuna/optuna-examples/blob/main/quickstart.ipynb


## File: source/installation.rst

Installation
============

Optuna supports Python 3.8 or newer.

We recommend to install Optuna via pip:

.. code-block:: bash

    $ pip install optuna

You can also install the development version of Optuna from master branch of Git repository:

.. code-block:: bash

    $ pip install git+https://github.com/optuna/optuna.git

You can also install Optuna via conda:

.. code-block:: bash

    $ conda install -c conda-forge optuna


## File: source/license_thirdparty.rst

:orphan:

Third-party License
===================

SciPy
-----


The Optuna contains the codes from SciPy project.


Copyright (c) 2001-2002 Enthought, Inc. 2003-2022, SciPy Developers.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above
   copyright notice, this list of conditions and the following
   disclaimer in the documentation and/or other materials provided
   with the distribution.

3. Neither the name of the copyright holder nor the names of its
   contributors may be used to endorse or promote products derived
   from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


fdlibm
------


 Copyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.

 Developed at SunPro, a Sun Microsystems, Inc. business.
 Permission to use, copy, modify, and distribute this
 software is freely granted, provided that this notice
 is preserved.


## File: source/privacy.rst

:orphan:

Privacy Policy
==============

Google Analytics
----------------

To collect information about how visitors use our website and to improve our services, we are using Google Analytics on this website. You can find out more about how Google Analytics works and about how information is collected on the Google Analytics terms of services and on Google's privacy policy.

- Google Analytics Terms of Service: http://www.google.com/analytics/terms/us.html
- Google Privacy Policy: https://policies.google.com/privacy?hl=en
- Google Analytics Opt-out Add-on: https://tools.google.com/dlpage/gaoptout?hl=en


## File: source/reference/artifacts.rst

.. module:: optuna.artifacts

optuna.artifacts
================

The :mod:`~optuna.artifacts` module provides the way to manage artifacts (output files) in Optuna.
Please also check :ref:`artifact_tutorial` and `our article <https://medium.com/optuna/file-management-during-llm-large-language-model-trainings-by-optuna-v4-0-0-artifact-store-5bdd5112f3c7>`__.
The storages covered by :mod:`~optuna.artifacts` are the following:

+-------------------------+----------------------------------------+
| Class Name              |           Supported Storage            |
+=========================+========================================+
| FileSystemArtifactStore | Local File System, Network File System |
+-------------------------+----------------------------------------+
| Boto3ArtifactStore      | Amazon S3 Compatible Object Storage    |
+-------------------------+----------------------------------------+
| GCSArtifactStore        | Google Cloud Storage                   |
+-------------------------+----------------------------------------+

.. note::
   The methods defined in each ``ArtifactStore`` are not intended to be directly accessed by library users.

.. note::
   As ``ArtifactStore`` does not officially provide user API for artifact removal, please refer to :ref:`remove_for_artifact_store` for the hack.

.. autoclass:: optuna.artifacts.FileSystemArtifactStore
   :no-members:

.. autoclass:: optuna.artifacts.Boto3ArtifactStore
   :no-members:

.. autoclass:: optuna.artifacts.GCSArtifactStore
   :no-members:

.. autoclass:: optuna.artifacts.Backoff
   :no-members:

.. autoclass:: optuna.artifacts.ArtifactMeta
   :no-members:

.. autofunction:: optuna.artifacts.upload_artifact

.. autofunction:: optuna.artifacts.get_all_artifact_meta

.. autofunction:: optuna.artifacts.download_artifact


## File: source/reference/cli.rst

.. module:: optuna.cli

optuna.cli
==========

The :mod:`~optuna.cli` module implements Optuna's command-line functionality.

For detail, please see the result of

.. code-block:: console

    $ optuna --help

.. seealso::
    The :ref:`cli` tutorial provides use-cases with examples.


## File: source/reference/distributions.rst

.. module:: optuna.distributions

optuna.distributions
====================

The :mod:`~optuna.distributions` module defines various classes representing probability distributions, mainly used to suggest initial hyperparameter values for an optimization trial. Distribution classes inherit from a library-internal :class:`~optuna.distributions.BaseDistribution`, and is initialized with specific parameters, such as the ``low`` and ``high`` endpoints for a :class:`~optuna.distributions.IntDistribution`.

Optuna users should not use distribution classes directly, but instead use utility functions provided by :class:`~optuna.trial.Trial` such as :meth:`~optuna.trial.Trial.suggest_int`.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   FloatDistribution
   IntDistribution
   CategoricalDistribution
   distribution_to_json
   json_to_distribution
   check_distribution_compatibility

The following classes are deprecated and will be removed in the future.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   UniformDistribution
   LogUniformDistribution
   DiscreteUniformDistribution
   IntUniformDistribution
   IntLogUniformDistribution


## File: source/reference/exceptions.rst

.. module:: optuna.exceptions

optuna.exceptions
=================

The :mod:`~optuna.exceptions` module defines Optuna-specific exceptions deriving from a base :class:`~optuna.exceptions.OptunaError` class. Of special importance for library users is the :class:`~optuna.exceptions.TrialPruned` exception to be raised if :func:`optuna.trial.Trial.should_prune` returns ``True`` for a trial that should be pruned.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   OptunaError
   TrialPruned
   CLIUsageError
   StorageInternalError
   DuplicatedStudyError
   UpdateFinishedTrialError


## File: source/reference/importance.rst

.. module:: optuna.importance

optuna.importance
=================

The :mod:`~optuna.importance` module provides functionality for evaluating hyperparameter importances based on completed trials in a given study. The utility function :func:`~optuna.importance.get_param_importances` takes a :class:`~optuna.study.Study` and optional evaluator as two of its inputs. The evaluator must derive from :class:`~optuna.importance.BaseImportanceEvaluator`, and is initialized as a :class:`~optuna.importance.FanovaImportanceEvaluator` by default when not passed in. Users implementing custom evaluators should refer to either :class:`~optuna.importance.FanovaImportanceEvaluator`, :class:`~optuna.importance.MeanDecreaseImpurityImportanceEvaluator`, or :class:`~optuna.importance.PedAnovaImportanceEvaluator` as a guide, paying close attention to the format of the return value from the Evaluator's ``evaluate`` function.

.. note::

   :class:`~optuna.importance.FanovaImportanceEvaluator` takes over 1 minute when given a study that contains 1000+ trials.
   We published `optuna-fast-fanova <https://github.com/optuna/optuna-fast-fanova>`__ library,
   that is a Cython accelerated fANOVA implementation. By using it, you can get hyperparameter
   importances within a few seconds.
   If ``n_trials`` is more than 10000, the Cython implementation takes more than a minute, so you can use :class:`~optuna.importance.PedAnovaImportanceEvaluator` instead, enabling the evaluation to finish in a second.


.. autosummary::
   :toctree: generated/
   :nosignatures:

   get_param_importances
   FanovaImportanceEvaluator
   MeanDecreaseImpurityImportanceEvaluator
   PedAnovaImportanceEvaluator


## File: source/reference/index.rst

API Reference
=============

.. toctree::
    :maxdepth: 1

    optuna
    artifacts
    cli
    distributions
    exceptions
    importance
    integration
    logging
    pruners
    samplers/index
    search_space
    storages
    study
    terminator
    trial
    visualization/index


## File: source/reference/integration.rst

.. module:: optuna.integration

optuna.integration
==================

The :mod:`~optuna.integration` module contains classes used to integrate Optuna with external machine learning frameworks.

.. note::
   Optuna's integration modules for third-party libraries have started migrating from Optuna itself to a package called
   `optuna-integration`. Please check the `repository <https://github.com/optuna/optuna-integration>`__ and
   the `documentation <https://optuna-integration.readthedocs.io/en/stable/index.html>`__.

For most of the ML frameworks supported by Optuna, the corresponding Optuna integration class serves only to implement a callback object and functions, compliant with the framework's specific callback API, to be called with each intermediate step in the model training. The functionality implemented in these callbacks across the different ML frameworks includes:

(1) Reporting intermediate model scores back to the Optuna trial using :func:`optuna.trial.Trial.report`,
(2) According to the results of :func:`optuna.trial.Trial.should_prune`, pruning the current model by raising :func:`optuna.TrialPruned`, and
(3) Reporting intermediate Optuna data such as the current trial number back to the framework, as done in :class:`~optuna.integration.MLflowCallback`.

For scikit-learn, an integrated :class:`~optuna.integration.OptunaSearchCV` estimator is available that combines scikit-learn BaseEstimator functionality with access to a class-level ``Study`` object.

Dependencies of each integration
--------------------------------

We summarize the necessary dependencies for each integration.

+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| Integration                                                                                                                                                                       | Dependencies                       |
+===================================================================================================================================================================================+====================================+
| `AllenNLP <https://github.com/optuna/optuna/tree/master/optuna/integration/allennlp>`__                                                                                           | allennlp, torch, psutil, jsonnet   |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `BoTorch <https://github.com/optuna/optuna/blob/master/optuna/integration/botorch.py>`__                                                                                          | botorch, gpytorch, torch           |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `CatBoost <https://github.com/optuna/optuna/blob/master/optuna/integration/catboost.py>`__                                                                                        | catboost                           |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `ChainerMN <https://github.com/optuna/optuna/blob/master/optuna/integration/chainermn.py>`__                                                                                      | chainermn                          |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `Chainer <https://github.com/optuna/optuna/blob/master/optuna/integration/chainer.py>`__                                                                                          | chainer                            |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `pycma <https://github.com/optuna/optuna/blob/master/optuna/integration/cma.py>`__                                                                                                | cma                                |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `Dask <https://github.com/optuna/optuna/blob/master/optuna/integration/dask.py>`__                                                                                                | distributed                        |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `FastAI <https://github.com/optuna/optuna/blob/master/optuna/integration/fastaiv2.py>`__                                                                                          | fastai                             |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `Keras <https://github.com/optuna/optuna/blob/master/optuna/integration/keras.py>`__                                                                                              | keras                              |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `LightGBMTuner <https://github.com/optuna/optuna/blob/master/optuna/integration/lightgbm.py>`__                                                                                   | lightgbm, scikit-learn             |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `LightGBMPruningCallback <https://github.com/optuna/optuna/blob/master/optuna/integration/lightgbm.py>`__                                                                         | lightgbm                           |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `MLflow <https://github.com/optuna/optuna/blob/master/optuna/integration/mlflow.py>`__                                                                                            | mlflow                             |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `MXNet <https://github.com/optuna/optuna/blob/master/optuna/integration/mxnet.py>`__                                                                                              | mxnet                              |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| PyTorch `Distributed <https://github.com/optuna/optuna/blob/master/optuna/integration/pytorch_distributed.py>`__                                                                  | torch                              |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| PyTorch (`Ignite <https://github.com/optuna/optuna/blob/master/optuna/integration/pytorch_ignite.py>`__)                                                                          | pytorch-ignite                     |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| PyTorch (`Lightning <https://github.com/optuna/optuna/blob/master/optuna/integration/pytorch_lightning.py>`__)                                                                    | pytorch-lightning                  |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `SHAP <https://github.com/optuna/optuna/blob/master/optuna/integration/shap.py>`__                                                                                                | scikit-learn, shap                 |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `Scikit-learn <https://github.com/optuna/optuna/blob/master/optuna/integration/sklearn.py>`__                                                                                     | pandas, scipy, scikit-learn        |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `SKorch <https://github.com/optuna/optuna/blob/master/optuna/integration/skorch.py>`__                                                                                            | skorch                             |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `TensorBoard <https://github.com/optuna/optuna/blob/master/optuna/integration/tensorboard.py>`__                                                                                  | tensorboard, tensorflow            |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `TensorFlow <https://github.com/optuna/optuna/blob/master/optuna/integration/tensorflow.py>`__                                                                                    | tensorflow, tensorflow-estimator   |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `TensorFlow + Keras <https://github.com/optuna/optuna/blob/master/optuna/integration/tfkeras.py>`__                                                                               | tensorflow                         |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `Weights & Biases <https://github.com/optuna/optuna/blob/master/optuna/integration/wandb.py>`__                                                                                   | wandb                              |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+
| `XGBoost <https://github.com/optuna/optuna/blob/master/optuna/integration/xgboost.py>`__                                                                                          | xgboost                            |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------+


## File: source/reference/logging.rst

.. module:: optuna.logging

optuna.logging
==============

The :mod:`~optuna.logging` module implements logging using the Python ``logging`` package. Library users may be especially interested in setting verbosity levels using :func:`~optuna.logging.set_verbosity` to one of ``optuna.logging.CRITICAL`` (aka ``optuna.logging.FATAL``), ``optuna.logging.ERROR``, ``optuna.logging.WARNING`` (aka ``optuna.logging.WARN``), ``optuna.logging.INFO``, or ``optuna.logging.DEBUG``.


.. autosummary::
   :toctree: generated/
   :nosignatures:

   get_verbosity
   set_verbosity
   disable_default_handler
   enable_default_handler
   disable_propagation
   enable_propagation


## File: source/reference/optuna.rst

.. module:: optuna

optuna
======

The :mod:`optuna` module is primarily used as an alias for basic Optuna functionality coded in other modules. Currently, two modules are aliased: (1) from :mod:`optuna.study`, functions regarding the Study lifecycle, and (2) from :mod:`optuna.exceptions`, the TrialPruned Exception raised when a trial is pruned.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   create_study
   load_study
   delete_study
   copy_study
   get_all_study_names
   get_all_study_summaries
   TrialPruned


## File: source/reference/pruners.rst

.. module:: optuna.pruners

optuna.pruners
==============

The :mod:`~optuna.pruners` module defines a :class:`~optuna.pruners.BasePruner` class characterized by an abstract :meth:`~optuna.pruners.BasePruner.prune` method, which, for a given trial and its associated study, returns a boolean value representing whether the trial should be pruned. This determination is made based on stored intermediate values of the objective function, as previously reported for the trial using :meth:`optuna.trial.Trial.report`. The remaining classes in this module represent child classes, inheriting from :class:`~optuna.pruners.BasePruner`, which implement different pruning strategies.

.. warning::
    Currently :mod:`~optuna.pruners` module is expected to be used only for single-objective optimization.

.. seealso::
    :ref:`pruning` tutorial explains the concept of the pruner classes and a minimal example.

.. seealso::
    :ref:`user_defined_pruner` tutorial could be helpful if you want to implement your own pruner classes.

.. autosummary::
    :toctree: generated/
    :nosignatures:

    BasePruner
    MedianPruner
    NopPruner
    PatientPruner
    PercentilePruner
    SuccessiveHalvingPruner
    HyperbandPruner
    ThresholdPruner
    WilcoxonPruner


## File: source/reference/samplers/index.rst

.. module:: optuna.samplers

optuna.samplers
===============

The :mod:`~optuna.samplers` module defines a base class for parameter sampling as described extensively in :class:`~optuna.samplers.BaseSampler`. The remaining classes in this module represent child classes, deriving from :class:`~optuna.samplers.BaseSampler`, which implement different sampling strategies.

.. seealso::
    :ref:`pruning` tutorial explains the overview of the sampler classes.

.. seealso::
    :ref:`user_defined_sampler` tutorial could be helpful if you want to implement your own sampler classes.

.. seealso::
    If you are unsure about which sampler to use, please consider using `AutoSampler <https://hub.optuna.org/samplers/auto_sampler/>`__, which automatically selects a sampler during optimization. For more detail, see `the article on AutoSampler <https://medium.com/optuna/autosampler-automatic-selection-of-optimization-algorithms-in-optuna-1443875fd8f9>`__.

+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
|                                  |         RandomSampler         |          GridSampler          |          TPESampler           |         CmaEsSampler          |                                NSGAIISampler                                |          QMCSampler           |           GPSampler           |       BoTorchSampler          |                               BruteForceSampler                               |
+==================================+===============================+===============================+===============================+===============================+=============================================================================+===============================+===============================+===============================+===============================================================================+
| Float parameters                 |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                           :math:`\blacktriangle`                            |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark` (:math:`\color{red}\times` for infinite domain)|
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Integer parameters               |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                           :math:`\blacktriangle`                            |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Categorical parameters           |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |                       :math:`\color{green}\checkmark`                       |    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Pruning                          |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |   :math:`\color{red}\times` (:math:`\blacktriangle` for single-objective)   |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |    :math:`\blacktriangle`     |                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Multivariate optimization        |    :math:`\blacktriangle`     |    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                           :math:`\blacktriangle`                            |    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                            :math:`\blacktriangle`                             |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Conditional search space         |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |                           :math:`\blacktriangle`                            |    :math:`\blacktriangle`     |    :math:`\blacktriangle`     |    :math:`\blacktriangle`     |                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Multi-objective optimization     |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|   :math:`\color{red}\times`   |:math:`\color{green}\checkmark` (:math:`\blacktriangle` for single-objective)|:math:`\color{green}\checkmark`|  :math:`\color{red}\times`    |:math:`\color{green}\checkmark`|                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Batch optimization               |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                       :math:`\color{green}\checkmark`                       |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Distributed optimization         |:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|:math:`\color{green}\checkmark`|                       :math:`\color{green}\checkmark`                       |:math:`\color{green}\checkmark`|    :math:`\blacktriangle`     |:math:`\color{green}\checkmark`|                        :math:`\color{green}\checkmark`                        |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Constrained optimization         |   :math:`\color{red}\times`   |   :math:`\color{red}\times`   |:math:`\color{green}\checkmark`|   :math:`\color{red}\times`   |                       :math:`\color{green}\checkmark`                       |   :math:`\color{red}\times`   | :math:`\color{red}\times`     |:math:`\color{green}\checkmark`|                           :math:`\color{red}\times`                           |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Time complexity (per trial) (*)  |         :math:`O(d)`          |        :math:`O(dn)`          |     :math:`O(dn \log n)`      |        :math:`O(d^3)`         |                           :math:`O(mp^2)` (\*\*\*)                          |         :math:`O(dn)`         |        :math:`O(n^3)`         |        :math:`O(n^3)`         |                                 :math:`O(d)`                                  |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+
| Recommended budgets (#trials)    | as many as one likes          | number of combinations        |          100 – 1000           |         1000 – 10000          |                                100 – 10000                                  | as many as one likes          |              – 500            |           10 – 100            |                            number of combinations                             |
| (**)                             |                               |                               |                               |                               |                                                                             |                               |                               |                               |                                                                               |
+----------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------------------------------------------------------+

.. note::
   :math:`\color{green}\checkmark`: Supports this feature.
   :math:`\blacktriangle`: Works, but inefficiently.
   :math:`\color{red}\times`: Causes an error, or has no interface.

    (*): We assumes that :math:`d` is the dimension of the search space, :math:`n` is the number of finished trials, :math:`m` is the number of objectives, and :math:`p` is the population size (algorithm specific parameter).
    This table shows the time complexity of the sampling algorithms. We may omit other terms that depend on the implementation in Optuna, including :math:`O(d)` to call the sampling methods and :math:`O(n)` to collect the completed trials.
    This means that, for example, the actual time complexity of :class:`~optuna.samplers.RandomSampler` is :math:`O(d+n+d) = O(d+n)`.
    From another perspective, with the exception of :class:`~optuna.samplers.NSGAIISampler`, all time complexity is written for single-objective optimization.

    (**): (1) The budget depends on the number of parameters and the number of objectives. (2) This budget includes ``n_startup_trials`` if a sampler has ``n_startup_trials`` as one of its arguments.

    (\*\*\*): This time complexity assumes that the number of population size :math:`p` and the number of parallelization are regular.
    This means that the number of parallelization should not exceed the number of population size :math:`p`.

.. note::
    Samplers initialize their random number generators by specifying ``seed`` argument at initialization.
    However, samplers reseed them when ``n_jobs!=1`` of :func:`optuna.study.Study.optimize` to avoid sampling duplicated parameters by using the same generator.
    Thus we can hardly reproduce the optimization results with ``n_jobs!=1``.
    For the same reason, make sure that use either ``seed=None`` or different ``seed`` values among processes with distributed optimization explained in :ref:`distributed` tutorial.

.. note::
    For float, integer, or categorical parameters, see :ref:`configurations` tutorial.

    For pruning, see :ref:`pruning` tutorial.

    For multivariate optimization, see :class:`~optuna.samplers.BaseSampler`. The multivariate optimization is implemented as :func:`~optuna.samplers.BaseSampler.sample_relative` in Optuna. Please check the concrete documents of samplers for more details.

    For conditional search space, see :ref:`configurations` tutorial and :class:`~optuna.samplers.TPESampler`. The ``group`` option of :class:`~optuna.samplers.TPESampler` allows :class:`~optuna.samplers.TPESampler` to handle the conditional search space.

    For multi-objective optimization, see :ref:`multi_objective` tutorial.

    For batch optimization, see :ref:`Batch-Optimization` tutorial. Note that the ``constant_liar`` option of :class:`~optuna.samplers.TPESampler` allows :class:`~optuna.samplers.TPESampler` to handle the batch optimization.

    For distributed optimization, see :ref:`distributed` tutorial. Note that the ``constant_liar`` option of :class:`~optuna.samplers.TPESampler` allows :class:`~optuna.samplers.TPESampler` to handle the distributed optimization.

    For constrained optimization, see an `example <https://github.com/optuna/optuna-examples/blob/main/multi_objective/botorch_simple.py>`__.

.. autosummary::
    :toctree: generated/
    :nosignatures:

    BaseSampler
    GridSampler
    RandomSampler
    TPESampler
    CmaEsSampler
    GPSampler
    PartialFixedSampler
    NSGAIISampler
    NSGAIIISampler
    QMCSampler
    BruteForceSampler

.. note::
    The following :mod:`optuna.samplers.nsgaii` module defines crossover operations used by :class:`~optuna.samplers.NSGAIISampler`.

.. toctree::
    :maxdepth: 1

    nsgaii


## File: source/reference/samplers/nsgaii.rst

.. module:: optuna.samplers.nsgaii

optuna.samplers.nsgaii
======================

The :mod:`~optuna.samplers.nsgaii` module defines crossover operations used by :class:`~optuna.samplers.NSGAIISampler`.

.. autosummary::
    :toctree: generated/
    :nosignatures:

    BaseCrossover
    UniformCrossover
    BLXAlphaCrossover
    SPXCrossover
    SBXCrossover
    VSBXCrossover
    UNDXCrossover


## File: source/reference/search_space.rst

.. module:: optuna.search_space

optuna.search_space
===================

The :mod:`~optuna.search_space` module provides functionality for controlling search space of parameters.


.. autosummary::
   :toctree: generated/
   :nosignatures:

   IntersectionSearchSpace
   intersection_search_space


## File: source/reference/storages.rst

.. module:: optuna.storages

optuna.storages
===============

The :mod:`~optuna.storages` module defines a :class:`~optuna.storages.BaseStorage` class which abstracts a backend database and provides library-internal interfaces to the read/write histories of the studies and trials. Library users who wish to use storage solutions other than the default :class:`~optuna.storages.InMemoryStorage` should use one of the child classes of :class:`~optuna.storages.BaseStorage` documented below.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   RDBStorage
   RetryFailedTrialCallback
   fail_stale_trials
   JournalStorage
   InMemoryStorage
   run_grpc_proxy_server
   GrpcStorageProxy

optuna.storages.journal
-----------------------

:class:`~optuna.storages.JournalStorage` requires its backend specification and here is the list of the supported backends:

.. note::
   If users would like to use any backends not supported by Optuna, it is possible to do so by creating a customized class by inheriting :class:`optuna.storages.journal.BaseJournalBackend`.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   journal.JournalFileBackend
   journal.JournalRedisBackend

Users can flexibly choose a lock object for :class:`~optuna.storages.journal.JournalFileBackend` and here is the list of supported lock objects:

.. autosummary::
   :toctree: generated/
   :nosignatures:

   journal.JournalFileSymlinkLock
   journal.JournalFileOpenLock

Deprecated Modules
------------------

.. note::
   The following modules are deprecated at v4.0.0 and will be removed in the future.
   Please use the modules defined in :mod:`optuna.storages.journal`.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   BaseJournalLogStorage
   JournalFileStorage
   JournalRedisStorage


## File: source/reference/study.rst

.. module:: optuna.study

optuna.study
============

The :mod:`~optuna.study` module implements the :class:`~optuna.study.Study` object and related functions. A public constructor is available for the :class:`~optuna.study.Study` class, but direct use of this constructor is not recommended. Instead, library users should create and load a :class:`~optuna.study.Study` using :func:`~optuna.study.create_study` and :func:`~optuna.study.load_study` respectively.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   Study
   create_study
   load_study
   delete_study
   copy_study
   get_all_study_names
   get_all_study_summaries
   MaxTrialsCallback
   StudyDirection
   StudySummary


## File: source/reference/terminator.rst

.. module:: optuna.terminator

optuna.terminator
=================

The :mod:`~optuna.terminator` module implements a mechanism for automatically terminating the optimization process, accompanied by a callback class for the termination and evaluators for the estimated room for improvement in the optimization and statistical error of the objective function. The terminator stops the optimization process when the estimated potential improvement is smaller than the statistical error.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   BaseTerminator
   Terminator
   BaseImprovementEvaluator
   RegretBoundEvaluator
   BestValueStagnationEvaluator
   EMMREvaluator
   BaseErrorEvaluator
   CrossValidationErrorEvaluator
   StaticErrorEvaluator
   MedianErrorEvaluator
   TerminatorCallback
   report_cross_validation_scores

For an example of using this module, please refer to `this example <https://github.com/optuna/optuna-examples/tree/main/terminator>`__.


## File: source/reference/trial.rst

.. module:: optuna.trial

optuna.trial
============

The :mod:`~optuna.trial` module contains :class:`~optuna.trial.Trial` related classes and functions.

A :class:`~optuna.trial.Trial` instance represents a process of evaluating an objective function. This instance is passed to an objective function and provides interfaces to get parameter suggestion, manage the trial's state, and set/get user-defined attributes of the trial, so that Optuna users can define a custom objective function through the interfaces. Basically, Optuna users only use it in their custom objective functions.

.. autosummary::
   :toctree: generated/
   :nosignatures:

   Trial
   FixedTrial
   FrozenTrial
   TrialState
   create_trial


## File: source/reference/visualization/index.rst

.. include:: ./generated/index.rst

.. note::
    The following :mod:`optuna.visualization.matplotlib` module uses Matplotlib as a backend.

.. toctree::
    :maxdepth: 1

    matplotlib/index

.. seealso::
    The :ref:`visualization` tutorial provides use-cases with examples.


## File: source/reference/visualization/matplotlib/index.rst

.. include:: ./generated/index.rst


## File: source/tutorial/index.rst

:orphan:

Tutorial
========

If you are new to Optuna or want a general introduction, we highly recommend the below video.

.. raw:: html

    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/P6NwZVl8ttc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <br />
    <br />
    <br />


Key Features
------------

Showcases Optuna's `Key Features <https://github.com/optuna/optuna/blob/master/README.md#key-features>`__.

1. :doc:`10_key_features/001_first`
2. :doc:`10_key_features/002_configurations`
3. :doc:`10_key_features/003_efficient_optimization_algorithms`
4. :doc:`10_key_features/004_distributed`
5. :doc:`10_key_features/005_visualization`


Recipes
-------

Showcases the recipes that might help you using Optuna with comfort.

- :doc:`20_recipes/001_rdb`
- :doc:`20_recipes/002_multi_objective`
- :doc:`20_recipes/003_attributes`
- :doc:`20_recipes/004_cli`
- :doc:`20_recipes/005_user_defined_sampler`
- :doc:`20_recipes/006_user_defined_pruner`
- :doc:`20_recipes/007_optuna_callback`
- :doc:`20_recipes/008_specify_params`
- :doc:`20_recipes/009_ask_and_tell`
- :doc:`20_recipes/010_reuse_best_trial`
- :doc:`20_recipes/011_journal_storage`
- `Human-in-the-loop Optimization with Optuna Dashboard <https://optuna-dashboard.readthedocs.io/en/stable/tutorials/hitl.html>`__
- :doc:`20_recipes/012_artifact_tutorial`
- :doc:`20_recipes/013_wilcoxon_pruner`

.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`__


## File: visualization_examples/GALLERY_HEADER.rst

.. _visualization-examples-index:

.. _general_visualization_examples:

optuna.visualization
====================

The :mod:`~optuna.visualization` module provides utility functions for plotting the optimization process using plotly and matplotlib. Plotting functions generally take a :class:`~optuna.study.Study` object and optional parameters are passed as a list to the ``params`` argument.

.. note::
    In the :mod:`optuna.visualization` module, the following functions use plotly to create figures, but `JupyterLab`_ cannot
    render them by default. Please follow this `installation guide`_ to show figures in
    `JupyterLab`_.
.. note::
    The :func:`~optuna.visualization.plot_param_importances` requires the Python package of `scikit-learn <https://github.com/scikit-learn/scikit-learn>`__.

    .. _JupyterLab: https://github.com/jupyterlab/jupyterlab
    .. _installation guide: https://github.com/plotly/plotly.py#jupyterlab-support


## File: visualization_matplotlib_examples/GALLERY_HEADER.rst

.. module:: optuna.visualization.matplotlib

matplotlib
==========

.. note::
    The following functions use Matplotlib as a backend.

.. _visualization-matplotlib-examples-index:

.. _general_visualization_matplotlib_examples:


# PYTHON FILES FROM ./optuna/tutorial/



## File: 10_key_features/001_first.py

```python
"""
.. _first:

Lightweight, versatile, and platform agnostic architecture
==========================================================

Optuna is entirely written in Python and has few dependencies.
This means that we can quickly move to the real example once you get interested in Optuna.


Quadratic Function Example
--------------------------

Usually, Optuna is used to optimize hyperparameters, but as an example,
let's optimize a simple quadratic function: :math:`(x - 2)^2`.
"""

###################################################################################################
# First of all, import :mod:`optuna`.

import optuna


###################################################################################################
# In optuna, conventionally functions to be optimized are named `objective`.


def objective(trial):
    x = trial.suggest_float("x", -10, 10)
    return (x - 2) ** 2


###################################################################################################
# This function returns the value of :math:`(x - 2)^2`. Our goal is to find the value of ``x``
# that minimizes the output of the ``objective`` function. This is the "optimization."
# During the optimization, Optuna repeatedly calls and evaluates the objective function with
# different values of ``x``.
#
# A :class:`~optuna.trial.Trial` object corresponds to a single execution of the objective
# function and is internally instantiated upon each invocation of the function.
#
# The `suggest` APIs (for example, :func:`~optuna.trial.Trial.suggest_float`) are called
# inside the objective function to obtain parameters for a trial.
# :func:`~optuna.trial.Trial.suggest_float` selects parameters uniformly within the range
# provided. In our example, from :math:`-10` to :math:`10`.
#
# To start the optimization, we create a study object and pass the objective function to method
# :func:`~optuna.study.Study.optimize` as follows.

study = optuna.create_study()
study.optimize(objective, n_trials=100)


###################################################################################################
# You can get the best parameter as follows.

best_params = study.best_params
found_x = best_params["x"]
print("Found x: {}, (x - 2)^2: {}".format(found_x, (found_x - 2) ** 2))

###################################################################################################
# We can see that the ``x`` value found by Optuna is close to the optimal value of ``2``.

###################################################################################################
# .. note::
#     When used to search for hyperparameters in machine learning,
#     usually the objective function would return the loss or accuracy
#     of the model.


###################################################################################################
# Study Object
# ------------
#
# Let us clarify the terminology in Optuna as follows:
#
# * **Trial**: A single call of the objective function
# * **Study**: An optimization session, which is a set of trials
# * **Parameter**: A variable whose value is to be optimized, such as ``x`` in the above example
#
# In Optuna, we use the study object to manage optimization.
# Method :func:`~optuna.study.create_study` returns a study object.
# A study object has useful properties for analyzing the optimization outcome.

###################################################################################################
# To get the dictionary of parameter name and parameter values:


study.best_params

###################################################################################################
# To get the best observed value of the objective function:

study.best_value


###################################################################################################
# To get the best trial:

study.best_trial


###################################################################################################
# To get all trials:

study.trials
for trial in study.trials[:2]:  # Show first two trials
    print(trial)

###################################################################################################
# To get the number of trials:

len(study.trials)


###################################################################################################
# By executing :func:`~optuna.study.Study.optimize` again, we can continue the optimization.

study.optimize(objective, n_trials=100)


###################################################################################################
# To get the updated number of trials:

len(study.trials)


###################################################################################################
# As the objective function is so easy that the last 100 trials don't improve the result.
# However, we can check the result again:
best_params = study.best_params
found_x = best_params["x"]
print("Found x: {}, (x - 2)^2: {}".format(found_x, (found_x - 2) ** 2))

```


## File: 10_key_features/002_configurations.py

```python
"""
.. _configurations:

Pythonic Search Space
=====================

For hyperparameter sampling, Optuna provides the following features:

- :func:`optuna.trial.Trial.suggest_categorical` for categorical parameters
- :func:`optuna.trial.Trial.suggest_int` for integer parameters
- :func:`optuna.trial.Trial.suggest_float` for floating point parameters

With optional arguments of ``step`` and ``log``, we can discretize or take the logarithm of
integer and floating point parameters.
"""

import optuna


def objective(trial):
    # Categorical parameter
    optimizer = trial.suggest_categorical("optimizer", ["MomentumSGD", "Adam"])

    # Integer parameter
    num_layers = trial.suggest_int("num_layers", 1, 3)

    # Integer parameter (log)
    num_channels = trial.suggest_int("num_channels", 32, 512, log=True)

    # Integer parameter (discretized)
    num_units = trial.suggest_int("num_units", 10, 100, step=5)

    # Floating point parameter
    dropout_rate = trial.suggest_float("dropout_rate", 0.0, 1.0)

    # Floating point parameter (log)
    learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-2, log=True)

    # Floating point parameter (discretized)
    drop_path_rate = trial.suggest_float("drop_path_rate", 0.0, 1.0, step=0.1)


###################################################################################################
# Defining Parameter Spaces
# -------------------------
#
# In Optuna, we define search spaces using familiar Python syntax including conditionals and loops.
#
# Also, you can use branches or loops depending on the parameter values.
#
# For more various use, see `examples <https://github.com/optuna/optuna-examples/>`__.

###################################################################################################
# - Branches:
import sklearn.ensemble
import sklearn.svm


def objective(trial):
    classifier_name = trial.suggest_categorical("classifier", ["SVC", "RandomForest"])
    if classifier_name == "SVC":
        svc_c = trial.suggest_float("svc_c", 1e-10, 1e10, log=True)
        classifier_obj = sklearn.svm.SVC(C=svc_c)
    else:
        rf_max_depth = trial.suggest_int("rf_max_depth", 2, 32, log=True)
        classifier_obj = sklearn.ensemble.RandomForestClassifier(max_depth=rf_max_depth)


###################################################################################################
# - Loops:
#
# .. code-block:: python
#
#     import torch
#     import torch.nn as nn
#
#
#     def create_model(trial, in_size):
#         n_layers = trial.suggest_int("n_layers", 1, 3)
#
#         layers = []
#         for i in range(n_layers):
#             n_units = trial.suggest_int("n_units_l{}".format(i), 4, 128, log=True)
#             layers.append(nn.Linear(in_size, n_units))
#             layers.append(nn.ReLU())
#             in_size = n_units
#         layers.append(nn.Linear(in_size, 10))
#
#         return nn.Sequential(*layers)


###################################################################################################
# Note on the Number of Parameters
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#
# The difficulty of optimization increases roughly exponentially with regard to the number of parameters. That is, the number of necessary trials increases exponentially when you increase the number of parameters, so it is recommended to not add unimportant parameters.

```


## File: 10_key_features/003_efficient_optimization_algorithms.py

```python
"""
.. _pruning:

Efficient Optimization Algorithms
=================================

Optuna enables efficient hyperparameter optimization by
adopting state-of-the-art algorithms for sampling hyperparameters and
pruning efficiently unpromising trials.

Sampling Algorithms
-------------------

Samplers basically continually narrow down the search space using the records of suggested parameter values and evaluated objective values,
leading to an optimal search space which giving off parameters leading to better objective values.
More detailed explanation of how samplers suggest parameters is in :class:`~optuna.samplers.BaseSampler`.

Optuna provides the following sampling algorithms:

- Grid Search implemented in :class:`~optuna.samplers.GridSampler`

- Random Search implemented in :class:`~optuna.samplers.RandomSampler`

- Tree-structured Parzen Estimator algorithm implemented in :class:`~optuna.samplers.TPESampler`

- CMA-ES based algorithm implemented in :class:`~optuna.samplers.CmaEsSampler`

- Gaussian process-based algorithm implemented in :class:`~optuna.samplers.GPSampler`

- Algorithm to enable partial fixed parameters implemented in :class:`~optuna.samplers.PartialFixedSampler`

- Nondominated Sorting Genetic Algorithm II implemented in :class:`~optuna.samplers.NSGAIISampler`

- A Quasi Monte Carlo sampling algorithm implemented in :class:`~optuna.samplers.QMCSampler`

The default sampler is :class:`~optuna.samplers.TPESampler`.

Switching Samplers
------------------

"""

import optuna


###################################################################################################
# By default, Optuna uses :class:`~optuna.samplers.TPESampler` as follows.

study = optuna.create_study()
print(f"Sampler is {study.sampler.__class__.__name__}")

###################################################################################################
# If you want to use different samplers for example :class:`~optuna.samplers.RandomSampler`
# and :class:`~optuna.samplers.CmaEsSampler`,

study = optuna.create_study(sampler=optuna.samplers.RandomSampler())
print(f"Sampler is {study.sampler.__class__.__name__}")

study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())
print(f"Sampler is {study.sampler.__class__.__name__}")


###################################################################################################
# Pruning Algorithms
# ------------------
#
# ``Pruners`` automatically stop unpromising trials at the early stages of the training (a.k.a., automated early-stopping).
# Currently :mod:`~optuna.pruners` module is expected to be used only for single-objective optimization.
#
# Optuna provides the following pruning algorithms:
#
# - Median pruning algorithm implemented in :class:`~optuna.pruners.MedianPruner`
#
# - Non-pruning algorithm implemented in :class:`~optuna.pruners.NopPruner`
#
# - Algorithm to operate pruner with tolerance implemented in :class:`~optuna.pruners.PatientPruner`
#
# - Algorithm to prune specified percentile of trials implemented in :class:`~optuna.pruners.PercentilePruner`
#
# - Asynchronous Successive Halving algorithm implemented in :class:`~optuna.pruners.SuccessiveHalvingPruner`
#
# - Hyperband algorithm implemented in :class:`~optuna.pruners.HyperbandPruner`
#
# - Threshold pruning algorithm implemented in :class:`~optuna.pruners.ThresholdPruner`
#
# - A pruning algorithm based on `Wilcoxon signed-rank test <https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test>`__ implemented in :class:`~optuna.pruners.WilcoxonPruner`
#
# We use :class:`~optuna.pruners.MedianPruner` in most examples,
# though basically it is outperformed by :class:`~optuna.pruners.SuccessiveHalvingPruner` and
# :class:`~optuna.pruners.HyperbandPruner` as in `this benchmark result <https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako>`__.
#
#
# Activating Pruners
# ------------------
# To turn on the pruning feature, you need to call :func:`~optuna.trial.Trial.report` and :func:`~optuna.trial.Trial.should_prune` after each step of the iterative training.
# :func:`~optuna.trial.Trial.report` periodically monitors the intermediate objective values.
# :func:`~optuna.trial.Trial.should_prune` decides termination of the trial that does not meet a predefined condition.
#
# We would recommend using integration modules for major machine learning frameworks.
# Exclusive list is :mod:`~optuna.integration` and usecases are available in `optuna-examples <https://github.com/optuna/optuna-examples/>`__.


import logging
import sys

import sklearn.datasets
import sklearn.linear_model
import sklearn.model_selection


def objective(trial):
    iris = sklearn.datasets.load_iris()
    classes = list(set(iris.target))
    train_x, valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(
        iris.data, iris.target, test_size=0.25, random_state=0
    )

    alpha = trial.suggest_float("alpha", 1e-5, 1e-1, log=True)
    clf = sklearn.linear_model.SGDClassifier(alpha=alpha)

    for step in range(100):
        clf.partial_fit(train_x, train_y, classes=classes)

        # Report intermediate objective value.
        intermediate_value = 1.0 - clf.score(valid_x, valid_y)
        trial.report(intermediate_value, step)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()

    return 1.0 - clf.score(valid_x, valid_y)


###################################################################################################
# Set up the median stopping rule as the pruning condition.

# Add stream handler of stdout to show the messages
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
study = optuna.create_study(pruner=optuna.pruners.MedianPruner())
study.optimize(objective, n_trials=20)

###################################################################################################
# As you can see, several trials were pruned (stopped) before they finished all of the iterations.
# The format of message is ``"Trial <Trial Number> pruned."``.

###################################################################################################
# Which Sampler and Pruner Should be Used?
# ----------------------------------------
#
# From the benchmark results which are available at `optuna/optuna - wiki "Benchmarks with Kurobako" <https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako>`__, at least for not deep learning tasks, we would say that
#
# * For :class:`~optuna.samplers.RandomSampler`, :class:`~optuna.pruners.MedianPruner` is the best.
# * For :class:`~optuna.samplers.TPESampler`, :class:`~optuna.pruners.HyperbandPruner` is the best.
#
# However, note that the benchmark is not deep learning.
# For deep learning tasks,
# consult the below table.
# This table is from the `Ozaki et al., Hyperparameter Optimization Methods: Overview and Characteristics, in IEICE Trans, Vol.J103-D No.9 pp.615-631, 2020 <https://doi.org/10.14923/transinfj.2019JDR0003>`__ paper,
# which is written in Japanese.
#
# +---------------------------+-----------------------------------------+---------------------------------------------------------------+
# | Parallel Compute Resource | Categorical/Conditional Hyperparameters | Recommended Algorithms                                        |
# +===========================+=========================================+===============================================================+
# | Limited                   | No                                      | TPE. GP-EI if search space is low-dimensional and continuous. |
# +                           +-----------------------------------------+---------------------------------------------------------------+
# |                           | Yes                                     | TPE. GP-EI if search space is low-dimensional and continuous  |
# +---------------------------+-----------------------------------------+---------------------------------------------------------------+
# | Sufficient                | No                                      | CMA-ES, Random Search                                         |
# +                           +-----------------------------------------+---------------------------------------------------------------+
# |                           | Yes                                     | Random Search or Genetic Algorithm                            |
# +---------------------------+-----------------------------------------+---------------------------------------------------------------+
#

###################################################################################################
# Integration Modules for Pruning
# -------------------------------
# To implement pruning mechanism in much simpler forms, Optuna provides integration modules for the following libraries.
#
# For the complete list of Optuna's integration modules, see :mod:`~optuna.integration`.
#
# For example, `LightGBMPruningCallback <https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.LightGBMPruningCallback.html>`__ introduces pruning without directly changing the logic of training iteration.
# (See also `example <https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_integration.py>`__ for the entire script.)
#
# .. code-block:: text
#
#         import optuna.integration
#
#         pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'validation-error')
#         gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])

```


## File: 10_key_features/004_distributed.py

```python
"""
.. _distributed:

Easy Parallelization
====================

It's straightforward to parallelize :func:`optuna.study.Study.optimize`.

If you want to manually execute Optuna optimization:

    1. start an RDB server (this example uses MySQL)
    2. create a study with ``--storage`` argument
    3. share the study among multiple nodes and processes

Of course, you can use Kubernetes as in `the kubernetes examples <https://github.com/optuna/optuna-examples/tree/main/kubernetes>`__.

To just see how parallel optimization works in Optuna, check the below video.

.. raw:: html

    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/J_aymk4YXhg?start=427" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


Create a Study
--------------

You can create a study using ``optuna create-study`` command.
Alternatively, in Python script you can use :func:`optuna.create_study`.


.. code-block:: bash

    $ mysql -u root -e "CREATE DATABASE IF NOT EXISTS example"
    $ optuna create-study --study-name "distributed-example" --storage "mysql://root@localhost/example"
    [I 2020-07-21 13:43:39,642] A new study created with name: distributed-example


Then, write an optimization script. Let's assume that ``foo.py`` contains the following code.

.. code-block:: python

    import optuna


    def objective(trial):
        x = trial.suggest_float("x", -10, 10)
        return (x - 2) ** 2


    if __name__ == "__main__":
        study = optuna.load_study(
            study_name="distributed-example", storage="mysql://root@localhost/example"
        )
        study.optimize(objective, n_trials=100)


Share the Study among Multiple Nodes and Processes
--------------------------------------------------

Finally, run the shared study from multiple processes.
For example, run ``Process 1`` in a terminal, and do ``Process 2`` in another one.
They get parameter suggestions based on shared trials' history.

Process 1:

.. code-block:: bash

    $ python foo.py
    [I 2020-07-21 13:45:02,973] Trial 0 finished with value: 45.35553104173011 and parameters: {'x': 8.73465151598285}. Best is trial 0 with value: 45.35553104173011.
    [I 2020-07-21 13:45:04,013] Trial 2 finished with value: 4.6002397305938905 and parameters: {'x': 4.144816945707463}. Best is trial 1 with value: 0.028194513284051464.
    ...

Process 2 (the same command as process 1):

.. code-block:: bash

    $ python foo.py
    [I 2020-07-21 13:45:03,748] Trial 1 finished with value: 0.028194513284051464 and parameters: {'x': 1.8320877810162361}. Best is trial 1 with value: 0.028194513284051464.
    [I 2020-07-21 13:45:05,783] Trial 3 finished with value: 24.45966755098074 and parameters: {'x': 6.945671597566982}. Best is trial 1 with value: 0.028194513284051464.
    ...

.. note::
    ``n_trials`` is the number of trials each process will run, not the total number of trials across all processes. For example, the script given above runs 100 trials for each process, 100 trials * 2 processes = 200 trials. :class:`optuna.study.MaxTrialsCallback` can ensure how many times trials will be performed across all processes.

.. note::
    We do not recommend SQLite for distributed optimizations at scale because it may cause deadlocks and serious performance issues. Please consider to use another database engine like PostgreSQL or MySQL.

.. note::
    Please avoid putting the SQLite database on NFS when running distributed optimizations. See also: https://www.sqlite.org/faq.html#q5

"""

```


## File: 10_key_features/005_visualization.py

```python
"""
.. _visualization:

Quick Visualization for Hyperparameter Optimization Analysis
============================================================

Optuna provides various visualization features in :mod:`optuna.visualization` to analyze optimization results visually.

Note that this tutorial requires `Plotly <https://plotly.com/python>`__ to be installed:

.. code-block:: console

      $ pip install plotly

      # Required if you are running this tutorial in Jupyter Notebook.
      $ pip install nbformat

If you prefer to use `Matplotlib <https://matplotlib.org/>`__ instead of Plotly, please run the following command:

.. code-block:: console

    $ pip install matplotlib

This tutorial walks you through this module by visualizing the optimization results of PyTorch model for FashionMNIST dataset.

For visualizing multi-objective optimization (i.e., the usage of :func:`optuna.visualization.plot_pareto_front`),
please refer to the tutorial of :ref:`multi_objective`.

.. note::
   By using `Optuna Dashboard <https://github.com/optuna/optuna-dashboard>`__, you can also check the optimization history,
   hyperparameter importances, hyperparameter relationships, etc. in graphs and tables.
   Please make your study persistent using :ref:`RDB backend <rdb>` and execute following commands to run Optuna Dashboard.

   .. code-block:: console

      $ pip install optuna-dashboard
      $ optuna-dashboard sqlite:///example-study.db

   Please check out `the GitHub repository <https://github.com/optuna/optuna-dashboard>`__ for more details.

   .. list-table::
      :header-rows: 1

      * - Manage Studies
        - Visualize with Interactive Graphs
      * - .. image:: https://user-images.githubusercontent.com/5564044/205545958-305f2354-c7cd-4687-be2f-9e46e7401838.gif
        - .. image:: https://user-images.githubusercontent.com/5564044/205545965-278cd7f4-da7d-4e2e-ac31-6d81b106cada.gif
"""

###################################################################################################
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision


import optuna

# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with
# `optuna.visualization.matplotlib` in the following examples.
from optuna.visualization import plot_contour
from optuna.visualization import plot_edf
from optuna.visualization import plot_intermediate_values
from optuna.visualization import plot_optimization_history
from optuna.visualization import plot_parallel_coordinate
from optuna.visualization import plot_param_importances
from optuna.visualization import plot_rank
from optuna.visualization import plot_slice
from optuna.visualization import plot_timeline


SEED = 13
torch.manual_seed(SEED)

DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
DIR = ".."
BATCHSIZE = 128
N_TRAIN_EXAMPLES = BATCHSIZE * 30
N_VALID_EXAMPLES = BATCHSIZE * 10


def define_model(trial):
    n_layers = trial.suggest_int("n_layers", 1, 2)
    layers = []

    in_features = 28 * 28
    for i in range(n_layers):
        out_features = trial.suggest_int("n_units_l{}".format(i), 64, 512)
        layers.append(nn.Linear(in_features, out_features))
        layers.append(nn.ReLU())

        in_features = out_features

    layers.append(nn.Linear(in_features, 10))
    layers.append(nn.LogSoftmax(dim=1))

    return nn.Sequential(*layers)


# Defines training and evaluation.
def train_model(model, optimizer, train_loader):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
        optimizer.zero_grad()
        F.nll_loss(model(data), target).backward()
        optimizer.step()


def eval_model(model, valid_loader):
    model.eval()
    correct = 0
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(valid_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            pred = model(data).argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    accuracy = correct / N_VALID_EXAMPLES

    return accuracy


###################################################################################################
# Define the objective function.
def objective(trial):
    train_dataset = torchvision.datasets.FashionMNIST(
        DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
    )
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
        batch_size=BATCHSIZE,
        shuffle=True,
    )

    val_dataset = torchvision.datasets.FashionMNIST(
        DIR, train=False, transform=torchvision.transforms.ToTensor()
    )
    val_loader = torch.utils.data.DataLoader(
        torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
        batch_size=BATCHSIZE,
        shuffle=True,
    )
    model = define_model(trial).to(DEVICE)

    optimizer = torch.optim.Adam(
        model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
    )

    for epoch in range(10):
        train_model(model, optimizer, train_loader)

        val_accuracy = eval_model(model, val_loader)
        trial.report(val_accuracy, epoch)

        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()

    return val_accuracy


###################################################################################################
study = optuna.create_study(
    direction="maximize",
    sampler=optuna.samplers.TPESampler(seed=SEED),
    pruner=optuna.pruners.MedianPruner(),
)
study.optimize(objective, n_trials=30, timeout=300)

###################################################################################################
# Plot functions
# --------------
# Visualize the optimization history. See :func:`~optuna.visualization.plot_optimization_history` for the details.
plot_optimization_history(study)

###################################################################################################
# Visualize the learning curves of the trials. See :func:`~optuna.visualization.plot_intermediate_values` for the details.
plot_intermediate_values(study)

###################################################################################################
# Visualize high-dimensional parameter relationships. See :func:`~optuna.visualization.plot_parallel_coordinate` for the details.
plot_parallel_coordinate(study)

###################################################################################################
# Select parameters to visualize.
plot_parallel_coordinate(study, params=["lr", "n_layers"])

###################################################################################################
# Visualize hyperparameter relationships. See :func:`~optuna.visualization.plot_contour` for the details.
plot_contour(study)

###################################################################################################
# Select parameters to visualize.
plot_contour(study, params=["lr", "n_layers"])

###################################################################################################
# Visualize individual hyperparameters as slice plot. See :func:`~optuna.visualization.plot_slice` for the details.
plot_slice(study)

###################################################################################################
# Select parameters to visualize.
plot_slice(study, params=["lr", "n_layers"])

###################################################################################################
# Visualize parameter importances. See :func:`~optuna.visualization.plot_param_importances` for the details.
plot_param_importances(study)

###################################################################################################
# Learn which hyperparameters are affecting the trial duration with hyperparameter importance.
optuna.visualization.plot_param_importances(
    study, target=lambda t: t.duration.total_seconds(), target_name="duration"
)

###################################################################################################
# Visualize empirical distribution function. See :func:`~optuna.visualization.plot_edf` for the details.
plot_edf(study)

###################################################################################################
# Visualize parameter relations with scatter plots colored by objective values. See :func:`~optuna.visualization.plot_rank` for the details.
plot_rank(study)

###################################################################################################
# Visualize the optimization timeline of performed trials. See :func:`~optuna.visualization.plot_timeline` for the details.
plot_timeline(study)

###################################################################################################
# Customize generated figures
# ---------------------------
# In :mod:`optuna.visualization` and :mod:`optuna.visualization.matplotlib`, a function returns an editable figure object:
# :class:`plotly.graph_objects.Figure` or :class:`matplotlib.axes.Axes` depending on the module.
# This allows users to modify the generated figure for their demand by using API of the visualization library.
# The following example replaces figure titles drawn by Plotly-based :func:`~optuna.visualization.plot_intermediate_values` manually.
fig = plot_intermediate_values(study)

fig.update_layout(
    title="Hyperparameter optimization for FashionMNIST classification",
    xaxis_title="Epoch",
    yaxis_title="Validation Accuracy",
)

```


## File: 20_recipes/001_rdb.py

```python
"""
.. _rdb:

Saving/Resuming Study with RDB Backend
==========================================

An RDB backend enables persistent experiments (i.e., to save and resume a study) as well as access to history of studies.
In addition, we can run multi-node optimization tasks with this feature, which is described in :ref:`distributed`.

In this section, let's try simple examples running on a local environment with SQLite DB.

.. note::
    You can also utilize other RDB backends, e.g., PostgreSQL or MySQL, by setting the storage argument to the DB's URL.
    Please refer to `SQLAlchemy's document <https://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls>`__ for how to set up the URL.


New Study
---------

We can create a persistent study by calling :func:`~optuna.study.create_study` function as follows.
An SQLite file ``example.db`` is automatically initialized with a new study record.
"""

import logging
import sys

import optuna

# Add stream handler of stdout to show the messages
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
study_name = "example-study"  # Unique identifier of the study.
storage_name = "sqlite:///{}.db".format(study_name)
study = optuna.create_study(study_name=study_name, storage=storage_name)

###################################################################################################
# To run a study, call :func:`~optuna.study.Study.optimize` method passing an objective function.


def objective(trial):
    x = trial.suggest_float("x", -10, 10)
    return (x - 2) ** 2


study.optimize(objective, n_trials=3)

###################################################################################################
# Resume Study
# ------------
#
# To resume a study, instantiate a :class:`~optuna.study.Study` object
# passing the study name ``example-study`` and the DB URL ``sqlite:///example-study.db``.


study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)
study.optimize(objective, n_trials=3)

###################################################################################################
# Note that the storage doesn't store the state of the instance of :mod:`~optuna.samplers`
# and :mod:`~optuna.pruners`.
# When we resume a study with a sampler whose ``seed`` argument is specified for
# reproducibility, you need to restore the sampler with using ``pickle`` as follows::
#
#     import pickle
#
#     # Save the sampler with pickle to be loaded later.
#     with open("sampler.pkl", "wb") as fout:
#         pickle.dump(study.sampler, fout)
#
#     restored_sampler = pickle.load(open("sampler.pkl", "rb"))
#     study = optuna.create_study(
#         study_name=study_name, storage=storage_name, load_if_exists=True, sampler=restored_sampler
#     )
#     study.optimize(objective, n_trials=3)
#

###################################################################################################
# Experimental History
# --------------------
#
# Note that this section requires the installation of `Pandas <https://pandas.pydata.org/>`__:
#
# .. code-block:: bash
#
#     $ pip install pandas
#
# We can access histories of studies and trials via the :class:`~optuna.study.Study` class.
# For example, we can get all trials of ``example-study`` as:

study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)
df = study.trials_dataframe(attrs=("number", "value", "params", "state"))

###################################################################################################
# The method :func:`~optuna.study.Study.trials_dataframe` returns a pandas dataframe like:

print(df)

###################################################################################################
# A :class:`~optuna.study.Study` object also provides properties
# such as :attr:`~optuna.study.Study.trials`, :attr:`~optuna.study.Study.best_value`,
# :attr:`~optuna.study.Study.best_params` (see also :ref:`first`).


print("Best params: ", study.best_params)
print("Best value: ", study.best_value)
print("Best Trial: ", study.best_trial)
print("Trials: ", study.trials)

```


## File: 20_recipes/002_multi_objective.py

```python
"""
.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `fvcore <https://github.com/facebookresearch/fvcore>`__ to measure FLOPS.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from fvcore.nn import FlopCountAnalysis

import optuna


DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
DIR = ".."
BATCHSIZE = 128
N_TRAIN_EXAMPLES = BATCHSIZE * 30
N_VALID_EXAMPLES = BATCHSIZE * 10


def define_model(trial):
    n_layers = trial.suggest_int("n_layers", 1, 3)
    layers = []

    in_features = 28 * 28
    for i in range(n_layers):
        out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
        layers.append(nn.Linear(in_features, out_features))
        layers.append(nn.ReLU())
        p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
        layers.append(nn.Dropout(p))

        in_features = out_features

    layers.append(nn.Linear(in_features, 10))
    layers.append(nn.LogSoftmax(dim=1))

    return nn.Sequential(*layers)


# Defines training and evaluation.
def train_model(model, optimizer, train_loader):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
        optimizer.zero_grad()
        F.nll_loss(model(data), target).backward()
        optimizer.step()


def eval_model(model, valid_loader):
    model.eval()
    correct = 0
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(valid_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            pred = model(data).argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    accuracy = correct / N_VALID_EXAMPLES

    flops = FlopCountAnalysis(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),)).total()
    return flops, accuracy


###################################################################################################
# Define multi-objective objective function.
# Objectives are FLOPS and accuracy.
def objective(trial):
    train_dataset = torchvision.datasets.FashionMNIST(
        DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
    )
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
        batch_size=BATCHSIZE,
        shuffle=True,
    )

    val_dataset = torchvision.datasets.FashionMNIST(
        DIR, train=False, transform=torchvision.transforms.ToTensor()
    )
    val_loader = torch.utils.data.DataLoader(
        torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
        batch_size=BATCHSIZE,
        shuffle=True,
    )
    model = define_model(trial).to(DEVICE)

    optimizer = torch.optim.Adam(
        model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
    )

    for epoch in range(10):
        train_model(model, optimizer, train_loader)
    flops, accuracy = eval_model(model, val_loader)
    return flops, accuracy


###################################################################################################
# Run multi-objective optimization
# --------------------------------
#
# If your optimization problem is multi-objective,
# Optuna assumes that you will specify the optimization direction for each objective.
# Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
# and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.
study = optuna.create_study(directions=["minimize", "maximize"])
study.optimize(objective, n_trials=30, timeout=300)

print("Number of finished trials: ", len(study.trials))


###################################################################################################
# Note that the following sections requires the installation of `Plotly <https://plotly.com/python>`__ for visualization
# and `scikit-learn <https://scikit-learn.org/stable>`__ for hyperparameter importance calculation:
#
# .. code-block:: console
#
#     $ pip install plotly
#     $ pip install scikit-learn
#     $ pip install nbformat  # Required if you are running this tutorial in Jupyter Notebook.
#
# Check trials on Pareto front visually.
optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])


###################################################################################################
# Fetch the list of trials on the Pareto front with :attr:`~optuna.study.Study.best_trials`.
#
# For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.

print(f"Number of trials on the Pareto front: {len(study.best_trials)}")

trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])
print("Trial with highest accuracy: ")
print(f"\tnumber: {trial_with_highest_accuracy.number}")
print(f"\tparams: {trial_with_highest_accuracy.params}")
print(f"\tvalues: {trial_with_highest_accuracy.values}")

###################################################################################################
# Learn which hyperparameters are affecting the flops most with hyperparameter importance.
optuna.visualization.plot_param_importances(
    study, target=lambda t: t.values[0], target_name="flops"
)

```


## File: 20_recipes/003_attributes.py

```python
"""
.. _attributes:

User Attributes
===============

This feature is to annotate experiments with user-defined attributes.
"""

###################################################################################################
# Adding User Attributes to Studies
# ---------------------------------
#
# A :class:`~optuna.study.Study` object provides :func:`~optuna.study.Study.set_user_attr` method
# to register a pair of key and value as an user-defined attribute.
# A key is supposed to be a ``str``, and a value be any object serializable with ``json.dumps``.

import sklearn.datasets
import sklearn.model_selection
import sklearn.svm

import optuna


study = optuna.create_study(storage="sqlite:///example.db")
study.set_user_attr("contributors", ["Akiba", "Sano"])
study.set_user_attr("dataset", "MNIST")


###################################################################################################
# We can access annotated attributes with :attr:`~optuna.study.Study.user_attrs` property.


study.user_attrs  # {'contributors': ['Akiba', 'Sano'], 'dataset': 'MNIST'}

###################################################################################################
# :class:`~optuna.study.StudySummary` object, which can be retrieved by
# :func:`~optuna.study.get_all_study_summaries`, also contains user-defined attributes.


study_summaries = optuna.get_all_study_summaries("sqlite:///example.db")
study_summaries[0].user_attrs  # {"contributors": ["Akiba", "Sano"], "dataset": "MNIST"}


###################################################################################################
# .. seealso::
#     ``optuna study set-user-attr`` command, which sets an attribute via command line interface.


###################################################################################################
# Adding User Attributes to Trials
# --------------------------------
#
# As with :class:`~optuna.study.Study`, a :class:`~optuna.trial.Trial` object provides
# :func:`~optuna.trial.Trial.set_user_attr` method.
# Attributes are set inside an objective function.


def objective(trial):
    iris = sklearn.datasets.load_iris()
    x, y = iris.data, iris.target

    svc_c = trial.suggest_float("svc_c", 1e-10, 1e10, log=True)
    clf = sklearn.svm.SVC(C=svc_c)
    accuracy = sklearn.model_selection.cross_val_score(clf, x, y).mean()

    trial.set_user_attr("accuracy", accuracy)

    return 1.0 - accuracy  # return error for minimization


study.optimize(objective, n_trials=1)

###################################################################################################
# We can access annotated attributes as:

study.trials[0].user_attrs

###################################################################################################
# Note that, in this example, the attribute is not annotated to a :class:`~optuna.study.Study`
# but a single :class:`~optuna.trial.Trial`.

```


## File: 20_recipes/004_cli.py

```python
"""
.. _cli:

Command-Line Interface
======================

.. csv-table::
   :header: Command, Description
   :widths: 20, 40
   :escape: \\

    ask, Create a new trial and suggest parameters.
    best-trial, Show the best trial.
    best-trials, Show a list of trials located at the Pareto front.
    create-study, Create a new study.
    delete-study, Delete a specified study.
    storage upgrade, Upgrade the schema of a storage.
    studies, Show a list of studies.
    study set-user-attr, Set a user attribute to a study.
    tell, Finish a trial\\, which was created by the ask command.
    trials, Show a list of trials.

Optuna provides command-line interface as shown in the above table.

Let us assume you are not in IPython shell and writing Python script files instead.
It is totally fine to write scripts like the following:
"""

import optuna


def objective(trial):
    x = trial.suggest_float("x", -10, 10)
    return (x - 2) ** 2


if __name__ == "__main__":
    study = optuna.create_study()
    study.optimize(objective, n_trials=100)
    print("Best value: {} (params: {})\n".format(study.best_value, study.best_params))

###################################################################################################
# However, if we cannot write ``objective`` explicitly in Python code such as developing a new
# drug in a lab, an interactive way is suitable.
# In Optuna CLI, :ref:`ask_and_tell` style commands provide such an interactive and flexible interface.
#
# Let us assume we minimize the objective value depending on a parameter ``x`` in :math:`[-10, 10]`
# and objective value is calculated via some experiments by hand.
# Even so, we can invoke the optimization as follows.
# Don't care about ``--storage sqlite:///example.db`` for now, which is described in :ref:`rdb`.
#
# .. code-block:: bash
#
#     $ STUDY_NAME=`optuna create-study --storage sqlite:///example.db`
#     $ optuna ask --storage sqlite:///example.db --study-name $STUDY_NAME --sampler TPESampler \
#          --search-space '{"x": {"name": "FloatDistribution", "attributes": {"step": null, "low": -10.0, "high": 10.0, "log": false}}}'
#
#
#     [I 2022-08-20 06:08:53,158] Asked trial 0 with parameters {'x': 2.512238141966016}.
#     {"number": 0, "params": {"x": 2.512238141966016}}
#
# The argument of ``--search-space`` option can be generated by using
# :func:`optuna.distributions.distribution_to_json`, for example,
# ``optuna.distributions.distribution_to_json(optuna.distributions.FloatDistribution(-10, 10))``.
# Please refer to :class:`optuna.distributions.FloatDistribution` and
# :class:`optuna.distributions.IntDistribution` for detailed explanations of their arguments.
#
# After conducting an experiment using the suggested parameter in the lab,
# we store the result to Optuna's study as follows:
#
# .. code-block:: bash
#
#     $ optuna tell --storage sqlite:///example.db --study-name $STUDY_NAME --trial-number 0 --values 0.7 --state complete
#     [I 2022-08-20 06:22:50,888] Told trial 0 with values [0.7] and state TrialState.COMPLETE.
#

```


## File: 20_recipes/005_user_defined_sampler.py

```python
"""
.. _user_defined_sampler:

User-Defined Sampler
====================

Thanks to user-defined samplers, you can:

- experiment your own sampling algorithms,
- implement task-specific algorithms to refine the optimization performance, or
- wrap other optimization libraries to integrate them into Optuna pipelines (e.g., `BoTorchSampler <https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.BoTorchSampler.html>`__).

This section describes the internal behavior of sampler classes and shows an example of implementing a user-defined sampler.


Overview of Sampler
-------------------

A sampler has the responsibility to determine the parameter values to be evaluated in a trial.
When a `suggest` API (e.g., :func:`~optuna.trial.Trial.suggest_float`) is called inside an objective function, the corresponding distribution object (e.g., :class:`~optuna.distributions.FloatDistribution`) is created internally. A sampler samples a parameter value from the distribution. The sampled value is returned to the caller of the `suggest` API and evaluated in the objective function.

To create a new sampler, you need to define a class that inherits :class:`~optuna.samplers.BaseSampler`.
The base class has three abstract methods;
:meth:`~optuna.samplers.BaseSampler.infer_relative_search_space`,
:meth:`~optuna.samplers.BaseSampler.sample_relative`, and
:meth:`~optuna.samplers.BaseSampler.sample_independent`.

As the method names imply, Optuna supports two types of sampling: one is **relative sampling** that can consider the correlation of the parameters in a trial, and the other is **independent sampling** that samples each parameter independently.

At the beginning of a trial, :meth:`~optuna.samplers.BaseSampler.infer_relative_search_space` is called to provide the relative search space for the trial. Then, :meth:`~optuna.samplers.BaseSampler.sample_relative` is invoked to sample relative parameters from the search space. During the execution of the objective function, :meth:`~optuna.samplers.BaseSampler.sample_independent` is used to sample parameters that don't belong to the relative search space.

.. note::
    Please refer to the document of :class:`~optuna.samplers.BaseSampler` for further details.


An Example: Implementing SimulatedAnnealingSampler
--------------------------------------------------

For example, the following code defines a sampler based on
`Simulated Annealing (SA) <https://en.wikipedia.org/wiki/Simulated_annealing>`__:
"""

import numpy as np
import optuna


class SimulatedAnnealingSampler(optuna.samplers.BaseSampler):
    def __init__(self, temperature=100):
        self._rng = np.random.RandomState()
        self._temperature = temperature  # Current temperature.
        self._current_trial = None  # Current state.

    def sample_relative(self, study, trial, search_space):
        if search_space == {}:
            return {}

        # Simulated Annealing algorithm.
        # 1. Calculate transition probability.
        prev_trial = study.trials[-2]
        if self._current_trial is None or prev_trial.value <= self._current_trial.value:
            probability = 1.0
        else:
            probability = np.exp(
                (self._current_trial.value - prev_trial.value) / self._temperature
            )
        self._temperature *= 0.9  # Decrease temperature.

        # 2. Transit the current state if the previous result is accepted.
        if self._rng.uniform(0, 1) < probability:
            self._current_trial = prev_trial

        # 3. Sample parameters from the neighborhood of the current point.
        # The sampled parameters will be used during the next execution of
        # the objective function passed to the study.
        params = {}
        for param_name, param_distribution in search_space.items():
            if (
                not isinstance(param_distribution, optuna.distributions.FloatDistribution)
                or (param_distribution.step is not None and param_distribution.step != 1)
                or param_distribution.log
            ):
                msg = (
                    "Only suggest_float() with `step` `None` or 1.0 and"
                    " `log` `False` is supported"
                )
                raise NotImplementedError(msg)

            current_value = self._current_trial.params[param_name]
            width = (param_distribution.high - param_distribution.low) * 0.1
            neighbor_low = max(current_value - width, param_distribution.low)
            neighbor_high = min(current_value + width, param_distribution.high)
            params[param_name] = self._rng.uniform(neighbor_low, neighbor_high)

        return params

    # The rest are unrelated to SA algorithm: boilerplate
    def infer_relative_search_space(self, study, trial):
        return optuna.search_space.intersection_search_space(study.get_trials(deepcopy=False))

    def sample_independent(self, study, trial, param_name, param_distribution):
        independent_sampler = optuna.samplers.RandomSampler()
        return independent_sampler.sample_independent(study, trial, param_name, param_distribution)


###################################################################################################
# .. note::
#    In favor of code simplicity, the above implementation doesn't support some features (e.g., maximization).
#    If you're interested in how to support those features, please see
#    `examples/samplers/simulated_annealing.py
#    <https://github.com/optuna/optuna-examples/blob/main/samplers/simulated_annealing_sampler.py>`__.
#
#
# You can use ``SimulatedAnnealingSampler`` in the same way as built-in samplers as follows:


def objective(trial):
    x = trial.suggest_float("x", -10, 10)
    y = trial.suggest_float("y", -5, 5)
    return x**2 + y


sampler = SimulatedAnnealingSampler()
study = optuna.create_study(sampler=sampler)
study.optimize(objective, n_trials=100)

best_trial = study.best_trial
print("Best value: ", best_trial.value)
print("Parameters that achieve the best value: ", best_trial.params)


###################################################################################################
# In this optimization, the values of ``x`` and ``y`` parameters are sampled by using
# ``SimulatedAnnealingSampler.sample_relative`` method.
#
# .. note::
#     Strictly speaking, in the first trial,
#     ``SimulatedAnnealingSampler.sample_independent`` method is used to sample parameter values.
#     Because :func:`~optuna.search_space.intersection_search_space` used in
#     ``SimulatedAnnealingSampler.infer_relative_search_space`` cannot infer the search space
#     if there are no complete trials.

```


## File: 20_recipes/006_user_defined_pruner.py

```python
"""
.. _user_defined_pruner:

User-Defined Pruner
===================

In :mod:`optuna.pruners`, we described how an objective function can optionally include
calls to a pruning feature which allows Optuna to terminate an optimization
trial when intermediate results do not appear promising. In this document, we
describe how to implement your own pruner, i.e., a custom strategy for
determining when to stop a trial.

Overview of Pruning Interface
-----------------------------

The :func:`~optuna.study.create_study` constructor takes, as an optional
argument, a pruner inheriting from :class:`~optuna.pruners.BasePruner`. The
pruner should implement the abstract method
:func:`~optuna.pruners.BasePruner.prune`, which takes arguments for the
associated :class:`~optuna.study.Study` and :class:`~optuna.trial.Trial` and
returns a boolean value: :obj:`True` if the trial should be pruned and :obj:`False`
otherwise. Using the Study and Trial objects, you can access all other trials
through the :func:`~optuna.study.Study.get_trials` method and, and from a trial,
its reported intermediate values through the
:func:`~optuna.trial.FrozenTrial.intermediate_values` (a
dictionary which maps an integer ``step`` to a float value).

You can refer to the source code of the built-in Optuna pruners as templates for
building your own. In this document, for illustration, we describe the
construction and usage of a simple (but aggressive) pruner which prunes trials
that are in last place compared to completed trials at the same step.

.. note::
    Please refer to the documentation of :class:`~optuna.pruners.BasePruner` or,
    for example, :class:`~optuna.pruners.ThresholdPruner` or
    :class:`~optuna.pruners.PercentilePruner` for more robust examples of pruner
    implementation, including error checking and complex pruner-internal logic.

An Example: Implementing ``LastPlacePruner``
--------------------------------------------

We aim to optimize the ``loss`` and ``alpha`` hyperparameters for a stochastic
gradient descent classifier (``SGDClassifier``) run on the sklearn iris dataset. We
implement a pruner which terminates a trial at a certain step if it is in last
place compared to completed trials at the same step. We begin considering
pruning after a "warmup" of 1 training step and 5 completed trials. For
demonstration purposes, we :func:`print` a diagnostic message from ``prune`` when
it is about to return :obj:`True` (indicating pruning).

It may be important to note that the ``SGDClassifier`` score, as it is evaluated on
a holdout set, decreases with enough training steps due to overfitting. This
means that a trial could be pruned even if it had a favorable (high) value on a
previous training set. After pruning, Optuna will take the intermediate value
last reported as the value of the trial.

"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier

import optuna
from optuna.pruners import BasePruner
from optuna.trial._state import TrialState


class LastPlacePruner(BasePruner):
    def __init__(self, warmup_steps, warmup_trials):
        self._warmup_steps = warmup_steps
        self._warmup_trials = warmup_trials

    def prune(self, study: "optuna.study.Study", trial: "optuna.trial.FrozenTrial") -> bool:
        # Get the latest score reported from this trial
        step = trial.last_step

        if step:  # trial.last_step == None when no scores have been reported yet
            this_score = trial.intermediate_values[step]

            # Get scores from other trials in the study reported at the same step
            completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))
            other_scores = [
                t.intermediate_values[step]
                for t in completed_trials
                if step in t.intermediate_values
            ]
            other_scores = sorted(other_scores)

            # Prune if this trial at this step has a lower value than all completed trials
            # at the same step. Note that steps will begin numbering at 0 in the objective
            # function definition below.
            if step >= self._warmup_steps and len(other_scores) > self._warmup_trials:
                if this_score < other_scores[0]:
                    print(f"prune() True: Trial {trial.number}, Step {step}, Score {this_score}")
                    return True

        return False


###################################################################################################
# Lastly, let's confirm the implementation is correct with the simple hyperparameter optimization.


def objective(trial):
    iris = load_iris()
    classes = np.unique(iris.target)
    X_train, X_valid, y_train, y_valid = train_test_split(
        iris.data, iris.target, train_size=100, test_size=50, random_state=0
    )

    loss = trial.suggest_categorical("loss", ["hinge", "log_loss", "perceptron"])
    alpha = trial.suggest_float("alpha", 0.00001, 0.001, log=True)
    clf = SGDClassifier(loss=loss, alpha=alpha, random_state=0)
    score = 0

    for step in range(0, 5):
        clf.partial_fit(X_train, y_train, classes=classes)
        score = clf.score(X_valid, y_valid)

        trial.report(score, step)

        if trial.should_prune():
            raise optuna.TrialPruned()

    return score


pruner = LastPlacePruner(warmup_steps=1, warmup_trials=5)
study = optuna.create_study(direction="maximize", pruner=pruner)
study.optimize(objective, n_trials=50)

```


## File: 20_recipes/007_optuna_callback.py

```python
"""
.. _optuna_callback:

Callback for Study.optimize
===========================

This tutorial showcases how to use & implement Optuna ``Callback`` for :func:`~optuna.study.Study.optimize`.

``Callback`` is called after every evaluation of ``objective``, and
it takes :class:`~optuna.study.Study` and :class:`~optuna.trial.FrozenTrial` as arguments, and does some work.

`MLflowCallback <https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.MLflowCallback.html>`__ is a great example.
"""

###################################################################################################
# Stop optimization after some trials are pruned in a row
# -------------------------------------------------------
#
# This example implements a stateful callback which stops the optimization
# if a certain number of trials are pruned in a row.
# The number of trials pruned in a row is specified by ``threshold``.


import optuna


class StopWhenTrialKeepBeingPrunedCallback:
    def __init__(self, threshold: int):
        self.threshold = threshold
        self._consequtive_pruned_count = 0

    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:
        if trial.state == optuna.trial.TrialState.PRUNED:
            self._consequtive_pruned_count += 1
        else:
            self._consequtive_pruned_count = 0

        if self._consequtive_pruned_count >= self.threshold:
            study.stop()


###################################################################################################
# This objective prunes all the trials except for the first 5 trials (``trial.number`` starts with 0).
def objective(trial):
    if trial.number > 4:
        raise optuna.TrialPruned

    return trial.suggest_float("x", 0, 1)


###################################################################################################
# Here, we set the threshold to ``2``: optimization finishes once two trials are pruned in a row.
# So, we expect this study to stop after 7 trials.
import logging
import sys

# Add stream handler of stdout to show the messages
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))

study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(2)
study = optuna.create_study()
study.optimize(objective, n_trials=10, callbacks=[study_stop_cb])


###################################################################################################
# As you can see in the log above, the study stopped after 7 trials as expected.

```


## File: 20_recipes/008_specify_params.py

```python
"""
.. _specify_params:

Specify Hyperparameters Manually
================================

It's natural that you have some specific sets of hyperparameters to try first such as initial learning rate
values and the number of leaves.
Also, it's possible that you've already tried those sets before having Optuna find better
sets of hyperparameters.

Optuna provides two APIs to support such cases:

1. Passing those sets of hyperparameters and let Optuna evaluate them - :func:`~optuna.study.Study.enqueue_trial`
2. Adding the results of those sets as completed ``Trial``\\s - :func:`~optuna.study.Study.add_trial`

.. _enqueue_trial_tutorial:

---------------------------------------------------------
First Scenario: Have Optuna evaluate your hyperparameters
---------------------------------------------------------

In this scenario, let's assume you have some out-of-box sets of hyperparameters but have not
evaluated them yet and decided to use Optuna to find better sets of hyperparameters.

Optuna has :func:`optuna.study.Study.enqueue_trial` which lets you pass those sets of
hyperparameters to Optuna and Optuna will evaluate them.

This section walks you through how to use this lit API with `LightGBM <https://lightgbm.readthedocs.io/en/stable/>`__.
"""

import lightgbm as lgb
import numpy as np
import sklearn.datasets
import sklearn.metrics
from sklearn.model_selection import train_test_split

import optuna


###################################################################################################
# Define the objective function.
def objective(trial):
    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)
    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)
    dtrain = lgb.Dataset(train_x, label=train_y)
    dvalid = lgb.Dataset(valid_x, label=valid_y)

    param = {
        "objective": "binary",
        "metric": "auc",
        "verbosity": -1,
        "boosting_type": "gbdt",
        "bagging_fraction": min(trial.suggest_float("bagging_fraction", 0.4, 1.0 + 1e-12), 1),
        "bagging_freq": trial.suggest_int("bagging_freq", 0, 7),
        "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
    }

    gbm = lgb.train(param, dtrain, valid_sets=[dvalid])

    preds = gbm.predict(valid_x)
    pred_labels = np.rint(preds)
    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)
    return accuracy


###################################################################################################
# Then, construct ``Study`` for hyperparameter optimization.

study = optuna.create_study(direction="maximize", pruner=optuna.pruners.MedianPruner())

###################################################################################################
# Here, we get Optuna evaluate some sets with larger ``"bagging_fraq"`` value and
# the default values.

study.enqueue_trial(
    {
        "bagging_fraction": 1.0,
        "bagging_freq": 0,
        "min_child_samples": 20,
    }
)

study.enqueue_trial(
    {
        "bagging_fraction": 0.75,
        "bagging_freq": 5,
        "min_child_samples": 20,
    }
)

import logging
import sys

# Add stream handler of stdout to show the messages to see Optuna works expectedly.
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
study.optimize(objective, n_trials=100, timeout=600)

###################################################################################################
# .. _add_trial_tutorial:
#
# ----------------------------------------------------------------------
# Second scenario: Have Optuna utilize already evaluated hyperparameters
# ----------------------------------------------------------------------
#
# In this scenario, let's assume you have some out-of-box sets of hyperparameters and
# you have already evaluated them but the results are not desirable so that you are thinking of
# using Optuna.
#
# Optuna has :func:`optuna.study.Study.add_trial` which lets you register those results
# to Optuna and then Optuna will sample hyperparameters taking them into account.
#
# In this section,  the ``objective`` is the same as the first scenario.

study = optuna.create_study(direction="maximize", pruner=optuna.pruners.MedianPruner())
study.add_trial(
    optuna.trial.create_trial(
        params={
            "bagging_fraction": 1.0,
            "bagging_freq": 0,
            "min_child_samples": 20,
        },
        distributions={
            "bagging_fraction": optuna.distributions.FloatDistribution(0.4, 1.0 + 1e-12),
            "bagging_freq": optuna.distributions.IntDistribution(0, 7),
            "min_child_samples": optuna.distributions.IntDistribution(5, 100),
        },
        value=0.94,
    )
)
study.add_trial(
    optuna.trial.create_trial(
        params={
            "bagging_fraction": 0.75,
            "bagging_freq": 5,
            "min_child_samples": 20,
        },
        distributions={
            "bagging_fraction": optuna.distributions.FloatDistribution(0.4, 1.0 + 1e-12),
            "bagging_freq": optuna.distributions.IntDistribution(0, 7),
            "min_child_samples": optuna.distributions.IntDistribution(5, 100),
        },
        value=0.95,
    )
)
study.optimize(objective, n_trials=100, timeout=600)

```


## File: 20_recipes/009_ask_and_tell.py

```python
"""
.. _ask_and_tell:

Ask-and-Tell Interface
=======================

Optuna has an `Ask-and-Tell` interface, which provides a more flexible interface for hyperparameter optimization.
This tutorial explains three use-cases when the ask-and-tell interface is beneficial:

- :ref:`Apply-optuna-to-an-existing-optimization-problem-with-minimum-modifications`
- :ref:`Define-and-Run`
- :ref:`Batch-Optimization`

.. _Apply-optuna-to-an-existing-optimization-problem-with-minimum-modifications:

----------------------------------------------------------------------------
Apply Optuna to an existing optimization problem with minimum modifications
----------------------------------------------------------------------------

Let's consider the traditional supervised classification problem; you aim to maximize the validation accuracy.
To do so, you train `LogisticRegression` as a simple model.
"""

import numpy as np
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

import optuna


X, y = make_classification(n_features=10)
X_train, X_test, y_train, y_test = train_test_split(X, y)

C = 0.01
clf = LogisticRegression(C=C)
clf.fit(X_train, y_train)
val_accuracy = clf.score(X_test, y_test)  # the objective

###################################################################################################
# Then you try to optimize hyperparameters ``C`` and ``solver`` of the classifier by using optuna.
# When you introduce optuna naively, you define an ``objective`` function
# such that it takes ``trial`` and calls ``suggest_*`` methods of ``trial`` to sample the hyperparameters:


def objective(trial):
    X, y = make_classification(n_features=10)
    X_train, X_test, y_train, y_test = train_test_split(X, y)

    C = trial.suggest_float("C", 1e-7, 10.0, log=True)
    solver = trial.suggest_categorical("solver", ("lbfgs", "saga"))

    clf = LogisticRegression(C=C, solver=solver)
    clf.fit(X_train, y_train)
    val_accuracy = clf.score(X_test, y_test)

    return val_accuracy


study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=10)

###################################################################################################
# This interface is not flexible enough.
# For example, if ``objective`` requires additional arguments other than ``trial``,
# you need to define a class as in
# `How to define objective functions that have own arguments? <../../faq.html#how-to-define-objective-functions-that-have-own-arguments>`__.
# The ask-and-tell interface provides a more flexible syntax to optimize hyperparameters.
# The following example is equivalent to the previous code block.

study = optuna.create_study(direction="maximize")

n_trials = 10
for _ in range(n_trials):
    trial = study.ask()  # `trial` is a `Trial` and not a `FrozenTrial`.

    C = trial.suggest_float("C", 1e-7, 10.0, log=True)
    solver = trial.suggest_categorical("solver", ("lbfgs", "saga"))

    clf = LogisticRegression(C=C, solver=solver)
    clf.fit(X_train, y_train)
    val_accuracy = clf.score(X_test, y_test)

    study.tell(trial, val_accuracy)  # tell the pair of trial and objective value

###################################################################################################
# The main difference is to use two methods: :func:`optuna.study.Study.ask`
# and :func:`optuna.study.Study.tell`.
# :func:`optuna.study.Study.ask` creates a trial that can sample hyperparameters, and
# :func:`optuna.study.Study.tell` finishes the trial by passing ``trial`` and an objective value.
# You can apply Optuna's hyperparameter optimization to your original code
# without an ``objective`` function.
#
# If you want to make your optimization faster with a pruner, you need to explicitly pass the state of trial
# to the argument of :func:`optuna.study.Study.tell` method as follows:
#
# .. code-block:: python
#
#    import numpy as np
#    from sklearn.datasets import load_iris
#    from sklearn.linear_model import SGDClassifier
#    from sklearn.model_selection import train_test_split
#
#    import optuna
#
#
#    X, y = load_iris(return_X_y=True)
#    X_train, X_valid, y_train, y_valid = train_test_split(X, y)
#    classes = np.unique(y)
#    n_train_iter = 100
#
#    # define study with hyperband pruner.
#    study = optuna.create_study(
#        direction="maximize",
#        pruner=optuna.pruners.HyperbandPruner(
#            min_resource=1, max_resource=n_train_iter, reduction_factor=3
#        ),
#    )
#
#    for _ in range(20):
#        trial = study.ask()
#
#        alpha = trial.suggest_float("alpha", 0.0, 1.0)
#
#        clf = SGDClassifier(alpha=alpha)
#        pruned_trial = False
#
#        for step in range(n_train_iter):
#            clf.partial_fit(X_train, y_train, classes=classes)
#
#            intermediate_value = clf.score(X_valid, y_valid)
#            trial.report(intermediate_value, step)
#
#            if trial.should_prune():
#                pruned_trial = True
#                break
#
#        if pruned_trial:
#            study.tell(trial, state=optuna.trial.TrialState.PRUNED)  # tell the pruned state
#        else:
#            score = clf.score(X_valid, y_valid)
#            study.tell(trial, score)  # tell objective value

###################################################################################################
# .. note::
#
#     :func:`optuna.study.Study.tell` method can take a trial number rather than the trial object.
#     ``study.tell(trial.number, y)`` is equivalent to ``study.tell(trial, y)``.


###################################################################################################
# .. _Define-and-Run:
#
# ---------------
# Define-and-Run
# ---------------
# The ask-and-tell interface supports both `define-by-run` and `define-and-run` APIs.
# This section shows the example of the `define-and-run` API
# in addition to the define-by-run example above.
#
# Define distributions for the hyperparameters before calling the
# :func:`optuna.study.Study.ask` method for define-and-run API.
# For example,

distributions = {
    "C": optuna.distributions.FloatDistribution(1e-7, 10.0, log=True),
    "solver": optuna.distributions.CategoricalDistribution(("lbfgs", "saga")),
}

###################################################################################################
# Pass ``distributions`` to :func:`optuna.study.Study.ask` method at each call.
# The retuned ``trial`` contains the suggested hyperparameters.

study = optuna.create_study(direction="maximize")
n_trials = 10
for _ in range(n_trials):
    trial = study.ask(distributions)  # pass the pre-defined distributions.

    # two hyperparameters are already sampled from the pre-defined distributions
    C = trial.params["C"]
    solver = trial.params["solver"]

    clf = LogisticRegression(C=C, solver=solver)
    clf.fit(X_train, y_train)
    val_accuracy = clf.score(X_test, y_test)

    study.tell(trial, val_accuracy)


###################################################################################################
# .. _Batch-Optimization:
#
# -------------------
# Batch Optimization
# -------------------
# The ask-and-tell interface enables us to optimize a batched objective for faster optimization.
# For example, parallelizable evaluation, operation over vectors, etc.

###################################################################################################
# The following objective takes batched hyperparameters ``xs`` and ``ys`` instead of a single
# pair of hyperparameters ``x`` and ``y`` and calculates the objective over the full vectors.


def batched_objective(xs: np.ndarray, ys: np.ndarray):
    return xs**2 + ys


###################################################################################################
# In the following example, the number of pairs of hyperparameters in a batch is :math:`10`,
# and ``batched_objective`` is evaluated three times.
# Thus, the number of trials is :math:`30`.
# Note that you need to store either ``trial_numbers`` or ``trial`` to call
# :func:`optuna.study.Study.tell` method after the batched evaluations.

batch_size = 10
study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())

for _ in range(3):
    # create batch
    trial_numbers = []
    x_batch = []
    y_batch = []
    for _ in range(batch_size):
        trial = study.ask()
        trial_numbers.append(trial.number)
        x_batch.append(trial.suggest_float("x", -10, 10))
        y_batch.append(trial.suggest_float("y", -10, 10))

    # evaluate batched objective
    x_batch = np.array(x_batch)
    y_batch = np.array(y_batch)
    objectives = batched_objective(x_batch, y_batch)

    # finish all trials in the batch
    for trial_number, objective in zip(trial_numbers, objectives):
        study.tell(trial_number, objective)

###################################################################################################
# .. tip::
#
#     :class:`optuna.samplers.TPESampler` class can take a boolean parameter ``constant_liar``. It
#     is recommended to set this value to ``True`` during batched optimization to avoid having
#     multiple workers evaluating similar parameter configurations. In particular, if each
#     objective function evaluation is costly and the durations of the running states are
#     significant, and/or the number of workers is high.

###################################################################################################
# .. tip::
#
#     :class:`optuna.samplers.CmaEsSampler` class can take a ``popsize`` attribute parameter
#     used as the initial population size for the CMA-ES algorithm. In the context of batched
#     optimization, it can  be set equal to a multiple of the batch size in order to benefit from
#     parallelizable operations.

```


## File: 20_recipes/010_reuse_best_trial.py

```python
"""
.. _reuse_best_trial:

Re-use the best trial
======================

In some cases, you may want to re-evaluate the objective function with the best
hyperparameters again after the hyperparameter optimization.

For example,

- You have found good hyperparameters with Optuna and want to run a similar `objective` function using the best hyperparameters found so far to further analyze the results, or
- You have optimized with Optuna using a partial dataset to reduce training time. After the hyperparameter tuning, you want to train the model using the whole dataset with the best hyperparameter values found.

:class:`~optuna.study.Study.best_trial` provides an interface to re-evaluate the objective function with the current best hyperparameter values.

This tutorial shows an example of how to re-run a different `objective` function with the current best values, like the first example above.


Investigating the best model further
-------------------------------------

Let's consider a classical supervised classification problem with Optuna as follows:
"""

from sklearn import metrics
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split


import optuna


def objective(trial):
    X, y = make_classification(n_features=10, random_state=1)
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

    C = trial.suggest_float("C", 1e-7, 10.0, log=True)

    clf = LogisticRegression(C=C)
    clf.fit(X_train, y_train)

    return clf.score(X_test, y_test)


study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=10)

print(study.best_trial.value)  # Show the best value.

###################################################################################################
# Suppose after the hyperparameter optimization, you want to calculate other evaluation metrics
# such as recall, precision, and f1-score on the same dataset.
# You can define another objective function that shares most of the ``objective``
# function to reproduce the model with the best hyperparameters.


def detailed_objective(trial):
    # Use same code objective to reproduce the best model
    X, y = make_classification(n_features=10, random_state=1)
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

    C = trial.suggest_float("C", 1e-7, 10.0, log=True)

    clf = LogisticRegression(C=C)
    clf.fit(X_train, y_train)

    # calculate more evaluation metrics
    pred = clf.predict(X_test)

    acc = metrics.accuracy_score(pred, y_test)
    recall = metrics.recall_score(pred, y_test)
    precision = metrics.precision_score(pred, y_test)
    f1 = metrics.f1_score(pred, y_test)

    return acc, f1, recall, precision


###################################################################################################
# Pass ``study.best_trial`` as the argument of ``detailed_objective``.

detailed_objective(study.best_trial)  # calculate acc, f1, recall, and precision

###################################################################################################
# The difference between :class:`~optuna.study.Study.best_trial` and ordinal trials
# ----------------------------------------------------------------------------------
#
# This uses :class:`~optuna.study.Study.best_trial`, which returns the `best_trial` as a
# :class:`~optuna.trial.FrozenTrial`.
# The :class:`~optuna.trial.FrozenTrial` is different from an active trial
# and behaves differently from :class:`~optuna.trial.Trial` in some situations.
# For example, pruning does not work because :class:`~optuna.trial.FrozenTrial.should_prune`
# always returns ``False``.
#
# .. note::
#     For multi-objective optimization as demonstrated by :ref:`multi_objective`,
#     :attr:`~optuna.study.Study.best_trials` returns a list of :class:`~optuna.trial.FrozenTrial`
#     on Pareto front. So we can re-use each trial in the list by the similar way above.

```


## File: 20_recipes/011_journal_storage.py

```python
"""
.. _journal_storage:

(File-based) Journal Storage
============================

Optuna provides :class:`~optuna.storages.JournalStorage`. With this feature, you can easily run a
distributed optimization over network using NFS as the shared storage, without need for setting up
RDB or Redis.

"""

import logging
import sys

import optuna


# Add stream handler of stdout to show the messages
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
study_name = "example-study"  # Unique identifier of the study.
file_path = "./optuna_journal_storage.log"
storage = optuna.storages.JournalStorage(
    optuna.storages.journal.JournalFileBackend(file_path),  # NFS path for distributed optimization
)

study = optuna.create_study(study_name=study_name, storage=storage)


def objective(trial):
    x = trial.suggest_float("x", -10, 10)
    return (x - 2) ** 2


study.optimize(objective, n_trials=3)

###################################################################################################
# Although the optimization in this example is too short to run in parallel, you can extend this
# example to write a optimization script which can be run in parallel.
#

###################################################################################################
# .. note::
#     In a Windows environment, an error message "A required privilege is not held by the client"
#     may appear. In this case, you can solve the problem with creating storage by specifying
#     :class:`~optuna.storages.journal.JournalFileOpenLock`. See the reference of
#     :class:`~optuna.storages.JournalStorage` for any details.

```


## File: 20_recipes/012_artifact_tutorial.py

```python
"""
.. _artifact_tutorial:

Optuna Artifacts Tutorial
=========================

.. contents:: Table of Contents
    :depth: 2

The artifact module of Optuna is a module designed for saving comparatively large attributes on a trial-by-trial basis in forms such
as files. Introduced from Optuna v3.3, this module finds a broad range of applications, such as utilizing snapshots of large size
models for hyperparameter tuning, optimizing massive chemical structures, and even human-in-the-loop optimization employing images
or sounds. Use of Optuna's artifact module allows you to handle data that would be too large to store in a database. Furthermore,
by integrating with `optuna-dashboard <https://github.com/optuna/optuna-dashboard>`__, saved artifacts can be automatically visualized
with the web UI, which significantly reduces the effort of experiment management.

TL;DR
-----

- The artifact module provides a simple way to save and use large data associated with trials.

- Saved artifacts can be visualized just by accessing the web page using optuna-dashboard, and downloading is also easy.

- Thanks to the abstraction of the artifact module, the backend (file system, AWS S3) can be easily switched.

- As the artifact module is tightly linked with Optuna, experiment management can be completed with the Optuna ecosystem alone, simplifying the code base.

Concepts
--------

.. list-table::
    :header-rows: 1

    * - Fig 1. Concepts of the "artifact".
    * - .. image:: https://github.com/optuna/optuna/assets/38826298/112e0b75-9d22-474b-85ea-9f3e0d75fa8d

An "artifact" is associated with an Optuna trial. In Optuna, the objective function is evaluated sequentially to search for the
maximum (or minimum) value. Each evaluation of the sequentially repeated objective function is called a trial. Normally, trials and
their associated attributes are saved via storage objects to files or RDBs, etc. For experiment management, you can also save and
use :attr:`optuna.trial.Trial.user_attrs` for each trial. However, these attributes are assumed to be integers, short strings, or other small data, which
are not suitable for storing large data. With Optuna's artifact module, users can save large data (such as model snapshots,
chemical structures, image and audio data, etc.) for each trial.

Also, while this tutorial does not touch upon it, it's possible to manage artifacts associated not only with trials but also with
studies. Please refer to the `official documentation <https://optuna.readthedocs.io/en/stable/reference/artifacts.html#optuna.artifacts.upload_artifact>`__
if you are interested in.

Situations where artifacts are useful
-------------------------------------

Artifacts are useful when you want to save data that is too large to be stored in RDB for each trial. For example, the artifact
module would be handy in situations like the following:

- Saving snapshots of machine learning models: Suppose you are tuning hyperparameters for a large-scale machine learning model like
  an LLM. The model is very large, and each round of learning (which corresponds to one trial in Optuna) takes time. To prepare for
  unexpected incidents during training (such as blackouts at the data center or a preemption of computation jobs by the scheduler),
  you may want to save snapshots of the model in the middle of training for each trial. These snapshots often tend to be large and
  are more suitable to be saved as some kinds of files than to be stored in RDB. In such cases, the artifact module is useful.

- Optimizing chemical structures: Suppose you are formulating and exploring a problem of finding stable chemical structures as a
  black-box optimization problem. Evaluating one chemical structure corresponds to one trial in Optuna, and that chemical structure
  is a complex and large one. It is not appropriate to store such chemical structure data in RDB. It is conceivable to save the
  chemical structure data in a specific file format, and in such a case, the artifact module is useful.

- Human-in-the-loop optimization of images: Suppose you are optimizing prompts for a generative model that outputs images. You
  sample the prompts using Optuna, output images using the generative model, and let humans rate the images for a Human-in-the-loop
  optimization process. Since the output images are large data, it is not appropriate to use RDB to store them, and in such cases,
  using the artifact module is well suited.

How Trials and Artifacts are Recorded
-------------------------------------

As explained so far, the artifact module is useful when you want to save large data for each trial. In this section, we explain
how artifacts work in the following two scenarios: first when SQLite + local file system-based artifact backend is used
(suitable when the entire optimization cycle is completed locally), and second when MySQL + AWS S3-based artifact backend is used
(suitable when you want to keep the data in a remote location).

Scenario 1: SQLite + file system-based artifact store
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. list-table::
    :header-rows: 1

    * - Fig 2. SQLite + file system-based artifact store.
    * - .. image:: https://github.com/optuna/optuna/assets/38826298/d41d042e-6b78-4615-bf96-05f73a47e9ea

First, we explain a simple case where the optimization is completed locally.

Normally, Optuna's optimization history is persisted into some kind of a database via storage objects. Here, let's consider a
method using SQLite, a lightweight RDB management system, as the backend. With SQLite, data is stored in a single file (e.g.,
``./example.db``). The optimization history comprises what parameters were sampled in each trial, what the evaluation values for those
parameters were, when each trial started and ended, etc. This file is in the SQLite format, and it is not suitable for storing
large data. Writing large data entries may cause performance degradation. Note that SQLite is not suitable for distributed parallel
optimization. If you want to perform that, please use MySQL as we will explain later, or :class:`~optuna.storages.JournalStorage`.

So, let's use the artifact module to save large data in a different format. Suppose the data is generated for each trial and you
want to save it in some format (e.g., png format if it's an image). The specific destination for saving the artifacts can be any
directory on the local file system (e.g., the ``./artifacts`` directory). When defining the objective function, you only need to save
and reference the data using the artifact module.

The simple pseudocode for the above case  would look something like this:

.. code-block:: python

    import os

    import optuna
    from optuna.artifacts import FileSystemArtifactStore
    from optuna.artifacts import upload_artifact
    from optuna.artifacts import download_artifact


    base_path = "./artifacts"
    os.makedirs(base_path, exist_ok=True)
    artifact_store = FileSystemArtifactStore(base_path=base_path)


    def objective(trial: optuna.Trial) -> float:
        ... = trial.suggest_float("x", -10, 10)

        # Creating and writing an artifact.
        file_path = generate_example(...)  # This function returns some kind of file.
        artifact_id = upload_artifact(
            artifact_store=artifact_store,
            file_path=file_path,
            study_or_trial=trial,
        )  # The return value is the artifact ID.
        trial.set_user_attr(
            "artifact_id", artifact_id
        )  # Save the ID in RDB so that it can be referenced later.

        return ...


    study = optuna.create_study(study_name="test_study", storage="sqlite:///example.db")
    study.optimize(objective, n_trials=100)

    # Downloading artifacts associated with the best trial.
    best_artifact_id = study.best_trial.user_attrs.get("artifact_id")
    download_file_path = ...  # Set the path to save the downloaded artifact.
    download_artifact(
        artifact_store=artifact_store, file_path=download_file_path, artifact_id=best_artifact_id
    )
    with open(download_file_path, "rb") as f:
        content = f.read().decode("utf-8")
    print(content)

Scenario 2: Remote MySQL RDB server + AWS S3 artifact store
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. list-table::
    :header-rows: 1

    * - Fig 3. Remote MySQL RDB server + AWS S3 artifact store.
    * - .. image:: https://github.com/optuna/optuna/assets/38826298/067efc85-1fad-4b46-a2be-626c64439d7b

Next, we explain the case where data is read and written remotely.

As the scale of optimization increases, it becomes difficult to complete all calculations locally. Optuna's storage objects can
persist data remotely by specifying a URL, enabling distributed optimization. Here, we will use MySQL as a remote relational
database server. MySQL is an open-source relational database management system and a well-known software used for various purposes.
For using MySQL with Optuna, the `tutorial <https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html>`__
can be a good reference. However, it is also not appropriate to read and write large data in a relational database like MySQL.

In Optuna, it is common to use the artifact module when you want to read and write such data for each trial. Unlike Scenario 1,
we distribute the optimization across computation nodes, so local file system-based backends will not work. Instead, we will use
AWS S3, an online cloud storage service, and Boto3, a framework for interacting with it from Python. As of v3.3, Optuna has a
built-in artifact store with this Boto3 backend.

The flow of data is shown in Figure 3. The information calculated in each trial, which corresponds to the optimization history
(excluding artifact information), is written to the MySQL server. On the other hand, the artifact information is written to AWS S3.
All workers conducting distributed optimization can read and write in parallel to each, and issues such as race conditions are
automatically resolved by Optuna's storage module and artifact module. As a result, although the actual data location changes
between artifact information and non-artifact information (the former is in AWS S3, the latter is in the MySQL RDB), users can
read and write data transparently. Translating the above process into simple pseudocode would look something like this:

.. code-block:: python

    import os

    import boto3
    from botocore.config import Config
    import optuna
    from optuna.artifact import upload_artifact
    from optuna.artifact import download_artifact
    from optuna.artifact.boto3 import Boto3ArtifactStore


    artifact_store = Boto3ArtifactStore(
        client=boto3.client(
            "s3",
            aws_access_key_id=os.environ[
                "AWS_ACCESS_KEY_ID"
            ],  # Assume that these environment variables are set up properly. The same applies below.
            aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"],
            endpoint_url=os.environ["S3_ENDPOINT"],
            config=Config(connect_timeout=30, read_timeout=30),
        ),
        bucket_name="example_bucket",
    )


    def objective(trial: optuna.Trial) -> float:
        ... = trial.suggest_float("x", -10, 10)

        # Creating and writing an artifact.
        file_path = generate_example(...)  # This function returns some kind of file.
        artifact_id = upload_artifact(
            artifact_store=artifact_store,
            file_path=file_path,
            study_or_trial=trial,
        )  # The return value is the artifact ID.
        trial.set_user_attr(
            "artifact_id", artifact_id
        )  # Save the ID in RDB so that it can be referenced later.

        return ...


    study = optuna.create_study(
        study_name="test_study",
        storage="mysql://USER:PASS@localhost:3306/test",  # Set the appropriate URL.
    )
    study.optimize(objective, n_trials=100)

    # Downloading artifacts associated with the best trial.
    best_artifact_id = study.best_trial.user_attrs.get("artifact_id")
    download_file_path = ...  # Set the path to save the downloaded artifact.
    download_artifact(
        artifact_store=artifact_store, file_path=download_file_path, artifact_id=best_artifact_id
    )
    with open(download_file_path, "rb") as f:
        content = f.read().decode("utf-8")
    print(content)

Example: Optimization of Chemical Structures
--------------------------------------------

In this section, we introduce an example of optimizing chemical structure using Optuna by utilizing the artifact module. We will
target relatively small structures, but the approach remains the same even for complex structures.

Consider the process of a specific molecule adsorbing onto another substance. In this process, the ease of adsorption reaction
changes depending on the position of the adsorbing molecule to the substance it is adsorbed onto. The ease of adsorption reaction
can be evaluated by the adsorption energy (the difference between the energy of the system after adsorption and before). By
formulating the problem as a minimization problem of an objective function that takes the positional relationship of the adsorbing
molecule as input and outputs the adsorption energy, this problem is solved as a black-box optimization problem.

First, let's import the necessary modules and define some helper functions. You need to install the ASE library for handling
chemical structures in addition to Optuna, so please install it with `pip install ase`.
"""

from __future__ import annotations

import io
import logging
import os
import sys
import tempfile

from ase import Atoms
from ase.build import bulk, fcc111, molecule, add_adsorbate
from ase.calculators.emt import EMT
from ase.io import write, read
from ase.optimize import LBFGS
import numpy as np
from optuna.artifacts import FileSystemArtifactStore
from optuna.artifacts import upload_artifact
from optuna.artifacts import download_artifact
from optuna.logging import get_logger
from optuna import create_study
from optuna import Trial


# Add stream handler of stdout to show the messages
get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))


def get_opt_energy(atoms: Atoms, fmax: float = 0.001) -> float:
    calculator = EMT()
    atoms.set_calculator(calculator)
    opt = LBFGS(atoms, logfile=None)
    opt.run(fmax=fmax)
    return atoms.get_total_energy()


def create_slab() -> tuple[Atoms, float]:
    calculator = EMT()
    bulk_atoms = bulk("Pt", cubic=True)
    bulk_atoms.calc = calculator

    a = np.mean(np.diag(bulk_atoms.cell))
    slab = fcc111("Pt", a=a, size=(4, 4, 4), vacuum=40.0, periodic=True)
    slab.calc = calculator
    E_slab = get_opt_energy(slab, fmax=1e-4)
    return slab, E_slab


def create_mol() -> tuple[Atoms, float]:
    calculator = EMT()
    mol = molecule("CO")
    mol.calc = calculator
    E_mol = get_opt_energy(mol, fmax=1e-4)
    return mol, E_mol


def atoms_to_json(atoms: Atoms) -> str:
    f = io.StringIO()
    write(f, atoms, format="json")
    return f.getvalue()


def json_to_atoms(atoms_str: str) -> Atoms:
    return read(io.StringIO(atoms_str), format="json")


def file_to_atoms(file_path: str) -> Atoms:
    return read(file_path, format="json")


###################################################################################################
# Each function is as follows.
#
# - ``get_opt_energy``: Takes a chemical structure, transitions it to a locally stable structure, and returns the energy after the transition.
# - ``create_slab``: Constructs the substance being adsorbed.
# - ``create_mol``: Constructs the molecule being adsorbed.
# - ``atoms_to_json``: Converts the chemical structure to a string.
# - ``json_to_atoms``: Converts the string to a chemical structure.
# - ``file_to_atoms``: Reads the string from a file and converts it to a chemical structure.
#
# Using these functions, the code to search for adsorption structures using Optuna is as follows. The objective function is defined
# as class ``Objective`` in order to carry the artifact store. In its ``__call__`` method, it retrieves the substance being adsorbed
# (``slab``) and the molecule being adsorbed (``mol``), then after sampling their positional relationship using Optuna (multiple
# ``trial.suggest_xxx`` methods), it triggers an adsorption reaction with the ``add_adsorbate`` function, transitions to a locally
# stable structure, then saves the structure in the artifact store and returns the adsorption energy.
#
# The ``main`` function contains the code to create a ``Study`` and execute optimization. When creating a ``Study``, a storage is
# specified using SQLite, and a back end using the local file system is used for the artifact store. In other words, it corresponds
# to Scenario 1 explained in the previous section. After performing 100 trials of optimization, it displays the information for the
# best trial, and finally saves the chemical structure as ``best_atoms.png``. The obtained ``best_atoms.png``` is shown in Figure 4.


class Objective:
    def __init__(self, artifact_store: FileSystemArtifactStore) -> None:
        self._artifact_store = artifact_store

    def __call__(self, trial: Trial) -> float:
        slab = json_to_atoms(trial.study.user_attrs["slab"])
        E_slab = trial.study.user_attrs["E_slab"]

        mol = json_to_atoms(trial.study.user_attrs["mol"])
        E_mol = trial.study.user_attrs["E_mol"]

        phi = 180.0 * trial.suggest_float("phi", -1, 1)
        theta = np.arccos(trial.suggest_float("theta", -1, 1)) * 180.0 / np.pi
        psi = 180 * trial.suggest_float("psi", -1, 1)
        x_pos = trial.suggest_float("x_pos", 0, 0.5)
        y_pos = trial.suggest_float("y_pos", 0, 0.5)
        z_hig = trial.suggest_float("z_hig", 1, 5)
        xy_position = np.matmul([x_pos, y_pos, 0], slab.cell)[:2]
        mol.euler_rotate(phi=phi, theta=theta, psi=psi)

        add_adsorbate(slab, mol, z_hig, xy_position)
        E_slab_mol = get_opt_energy(slab, fmax=1e-2)

        write(f"./tmp/{trial.number}.json", slab, format="json")
        artifact_id = upload_artifact(
            artifact_store=self._artifact_store,
            file_path=f"./tmp/{trial.number}.json",
            study_or_trial=trial,
        )
        trial.set_user_attr("structure", artifact_id)

        return E_slab_mol - E_slab - E_mol


def main():
    study = create_study(
        study_name="test_study",
        storage="sqlite:///example.db",
        load_if_exists=True,
    )

    slab, E_slab = create_slab()
    study.set_user_attr("slab", atoms_to_json(slab))
    study.set_user_attr("E_slab", E_slab)

    mol, E_mol = create_mol()
    study.set_user_attr("mol", atoms_to_json(mol))
    study.set_user_attr("E_mol", E_mol)

    os.makedirs("./tmp", exist_ok=True)

    base_path = "./artifacts"
    os.makedirs(base_path, exist_ok=True)
    artifact_store = FileSystemArtifactStore(base_path=base_path)
    study.optimize(Objective(artifact_store), n_trials=3)
    print(
        f"Best trial is #{study.best_trial.number}\n"
        f"    Its adsorption energy is {study.best_value}\n"
        f"    Its adsorption position is\n"
        f"        phi  : {study.best_params['phi']}\n"
        f"        theta: {study.best_params['theta']}\n"
        f"        psi. : {study.best_params['psi']}\n"
        f"        x_pos: {study.best_params['x_pos']}\n"
        f"        y_pos: {study.best_params['y_pos']}\n"
        f"        z_hig: {study.best_params['z_hig']}"
    )

    best_artifact_id = study.best_trial.user_attrs["structure"]

    with tempfile.TemporaryDirectory() as tmpdir_name:
        download_file_path = os.path.join(tmpdir_name, f"{best_artifact_id}.json")
        download_artifact(
            artifact_store=artifact_store,
            file_path=download_file_path,
            artifact_id=best_artifact_id,
        )

        best_atoms = file_to_atoms(download_file_path)
        print(best_atoms)
        write("best_atoms.png", best_atoms, rotation=("315x,0y,0z"))


if __name__ == "__main__":
    main()

###################################################################################################
# .. list-table::
#     :header-rows: 1
#
#     * - Fig 4. The chemical structure obtained by the above code.
#     * - .. image:: https://github.com/optuna/optuna/assets/38826298/c6bd62fd-599a-424e-8c2c-ca88af85cc63
#
# As shown above, it is convenient to use the artifact module when performing the optimization of chemical structures with Optuna.
# In the case of small structures or fewer trial numbers, it's fine to convert it to a string and save it directly in the RDB.
# However, when dealing with complex structures or performing large-scale searches, it's better to save it outside the RDB to
# avoid overloading it, such as in an external file system or AWS S3.
#
# Conclusion
# ----------
#
# The artifact module is a useful feature when you want to save relatively large data for each trial. It can be used for various
# purposes such as saving snapshots of machine learning models, optimizing chemical structures, and human-in-the-loop optimization
# of images and sounds. It's a powerful assistant for black-box optimization with Optuna. Also, if there are ways to use it that
# we, the Optuna committers, haven't noticed, please let us know on GitHub discussions. Have a great optimization life with Optuna!

```


## File: 20_recipes/013_wilcoxon_pruner.py

```python
"""
.. _wilcoxon_pruner:

Early-stopping independent evaluations by Wilcoxon pruner
============================================================

This tutorial showcases Optuna's :class:`~optuna.pruners.WilcoxonPruner`.
This pruner is effective for objective functions that averages multiple evaluations.

We solve `Traveling Salesman Problem (TSP) <https://en.wikipedia.org/w/index.php?title=Travelling_salesman_problem&oldid=1211575788>`__
by `Simulated Annealing (SA) <https://en.wikipedia.org/w/index.php?title=Simulated_annealing&oldid=1187355062>`__.

Overview: Solving Traveling Salesman Problem with Simulated Annealing
----------------------------------------------------------------------------

Traveling Salesman Problem (TSP) is a classic problem in combinatorial optimization
that involves finding the shortest possible route for a salesman
who needs to visit a set of cities, each exactly once, and return to the starting city.
TSP has been extensively studied in fields such as mathematics, computer science,
and operations research, and has numerous practical applications in logistics,
manufacturing, and DNA sequencing, among others.
The problem is classified as NP-hard, so approximation algorithms or
heuristic methods are commonly employed for larger instances.

One simple heuristic method applicable to TSP is simulated annealing (SA).
SA starts with an initial solution (it can be constructed by a simpler heuristic
like greedy method), and it randomly checks the neighborhood (defined later)
of the solution. If a neighbor is better, the solution is updated to the neighbor.
If the neighbor is worse, SA still updates the solution to the neighbor with
probability :math:`e^{-\\Delta c / T}`, where
:math:`\\Delta c (> 0)` is the difference of
the cost (sum of the distance) between the new solution and the old one and
:math:`T` is a parameter called "temperature". The temperature controls
how much worsening of the solution is tolerated to escape from the local minimum
(high means more tolerant). If the temperature is too low, SA will quickly
fall into a local minimum; if the temperature is too high, SA will be like
a random walk and the optimization will be inefficient. Typically, we set a
"temperature schedule" that starts from a high temperature and gradually
decreases to zero.

There are several ways to define neighborhood for TSP, but we use a
simple neighborhood called `2-opt <https://en.wikipedia.org/w/index.php?title=2-opt&oldid=1194969927>`__. 2-opt neighbor chooses a path in
the current solution and reverses the visiting order in the path.
For example, if the initial solution is `a→b→c→d→e→a`, `a→d→c→b→e→a` is
a 2-opt neighbor (the path from `b` to `d` is reversed).
This neighborhood is good because computing the difference of the cost
can be done in constant time (we only need to care about the start
and the end of the chosen path).

Main Tutorial: Tuning SA Parameters for TSP
====================================================

First, let's import some packages and define the parameters setting of SA
and the cost function of TSP.
"""  # NOQA

from dataclasses import dataclass
import math

import numpy as np
import optuna
import plotly.graph_objects as go
from numpy.linalg import norm


@dataclass
class SAOptions:
    max_iter: int = 10000
    T0: float = 1.0
    alpha: float = 2.0
    patience: int = 50


def tsp_cost(vertices: np.ndarray, idxs: np.ndarray) -> float:
    return norm(vertices[idxs] - vertices[np.roll(idxs, 1)], axis=-1).sum()


###################################################################################################
# Greedy solution for initial guess.


def tsp_greedy(vertices: np.ndarray) -> np.ndarray:
    idxs = [0]
    for _ in range(len(vertices) - 1):
        dists_from_last = norm(vertices[idxs[-1], None] - vertices, axis=-1)
        dists_from_last[idxs] = np.inf
        idxs.append(np.argmin(dists_from_last))
    return np.array(idxs)


###################################################################################################
# .. note::
#     For simplicity of implementation, we use SA with the 2-opt neighborhood to solve TSP,
#     but note that this is far from the "best" way to solve TSP. There are significantly more
#     advanced methods than this method.


###################################################################################################
# The implementation of SA with 2-opt neighborhood is following.


def tsp_simulated_annealing(vertices: np.ndarray, options: SAOptions) -> np.ndarray:

    def temperature(t: float):
        assert 0.0 <= t and t <= 1.0
        return options.T0 * (1 - t) ** options.alpha

    N = len(vertices)

    idxs = tsp_greedy(vertices)
    cost = tsp_cost(vertices, idxs)
    best_idxs = idxs.copy()
    best_cost = cost
    remaining_patience = options.patience

    for iter in range(options.max_iter):

        i = np.random.randint(0, N)
        j = (i + 2 + np.random.randint(0, N - 3)) % N
        i, j = min(i, j), max(i, j)
        # Reverse the order of vertices between range [i+1, j].

        # cost difference by 2-opt reversal
        delta_cost = (
            -norm(vertices[idxs[(i + 1) % N]] - vertices[idxs[i]])
            - norm(vertices[idxs[j]] - vertices[idxs[(j + 1) % N]])
            + norm(vertices[idxs[i]] - vertices[idxs[j]])
            + norm(vertices[idxs[(i + 1) % N]] - vertices[idxs[(j + 1) % N]])
        )
        temp = temperature(iter / options.max_iter)
        if delta_cost <= 0.0 or np.random.random() < math.exp(-delta_cost / temp):
            # accept the 2-opt reversal
            cost += delta_cost
            idxs[i + 1 : j + 1] = idxs[i + 1 : j + 1][::-1]
            if cost < best_cost:
                best_idxs[:] = idxs
                best_cost = cost
                remaining_patience = options.patience

        if cost > best_cost:
            # If the best solution is not updated for "patience" iteratoins,
            # restart from the best solution.
            remaining_patience -= 1
            if remaining_patience == 0:
                idxs[:] = best_idxs
                cost = best_cost
                remaining_patience = options.patience

    return best_idxs


###################################################################################################
# We make a random dataset of TSP.


def make_dataset(num_vertex: int, num_problem: int, seed: int = 0) -> np.ndarray:
    rng = np.random.default_rng(seed=seed)
    return rng.random((num_problem, num_vertex, 2))


dataset = make_dataset(
    num_vertex=100,
    num_problem=50,
)

N_TRIALS = 50


###################################################################################################
# We set a very small number of SA iterations for demonstration purpose.
# In practice, you should set a larger number of iterations (e.g., 1000000).


N_SA_ITER = 10000


###################################################################################################
# We counts the number of evaluation to know how many problems is pruned.


num_evaluation = 0


###################################################################################################
# In this tutorial, we optimize three parameters: ``T0``, ``alpha``, and ``patience``.
#
# ``T0`` and ``alpha`` defining the temperature schedule
# ---------------------------------------------------------------------------------------
#
# In simulated annealing, it is important to determine a good temperature scheduling, but
# there is no "silver schedule" that is good for all problems, so we must tune the schedule
# for this problem.
# This code parametrizes the temperature as a monomial function ``T0 * (1 - t) ** alpha``, where
# `t` progresses from 0 to 1. We try to optimize the two parameters ``T0`` and ``alpha``.
#
# ``patience``
# -----------------------------
#
# This parameter specifies a threshold of how many iterations we allow the annealing process
# continue without updating the best value. Practically, simulated annealing often drives
# the solution far away from the current best solution, and rolling back to the best solution
# periodically often improves optimization efficiency a lot. However, if the rollback happens
# too often, the optimization may get stuck in a local optimum, so we must tune the threshold
# to a sensible amount.
#
# .. note::
#     Some samplers, including the default ``TPESampler``, currently cannot utilize the
#     information of pruned trials effectively (especially when the last intermediate value
#     is not the best approximation to the final objective function).
#     As a workaround for this issue, you can return an estimation of the final value
#     (e.g., the average of all evaluated values) when ``trial.should_prune()`` returns ``True``,
#     instead of `raise optuna.TrialPruned()`.
#     This will improve the sampler performance.


###################################################################################################
# We define the objective function to be optimized as follows.
# We early stop the evaluation by using the pruner.


def objective(trial: optuna.Trial) -> float:
    global num_evaluation
    options = SAOptions(
        max_iter=N_SA_ITER,
        T0=trial.suggest_float("T0", 0.01, 10.0, log=True),
        alpha=trial.suggest_float("alpha", 1.0, 10.0, log=True),
        patience=trial.suggest_int("patience", 10, 1000, log=True),
    )
    results = []

    # For best results, shuffle the evaluation order in each trial.
    instance_ids = np.random.permutation(len(dataset))
    for instance_id in instance_ids:
        num_evaluation += 1
        result_idxs = tsp_simulated_annealing(vertices=dataset[instance_id], options=options)
        result_cost = tsp_cost(dataset[instance_id], result_idxs)
        results.append(result_cost)

        trial.report(result_cost, instance_id)
        if trial.should_prune():
            # Return the current predicted value instead of raising `TrialPruned`.
            # This is a workaround to tell the Optuna about the evaluation
            # results in pruned trials.
            return sum(results) / len(results)

    return sum(results) / len(results)


###################################################################################################
# We use ``TPESampler`` with ``WilcoxonPruner``.


np.random.seed(0)
sampler = optuna.samplers.TPESampler(seed=1)
pruner = optuna.pruners.WilcoxonPruner(p_threshold=0.1)
study = optuna.create_study(direction="minimize", sampler=sampler, pruner=pruner)
study.enqueue_trial({"T0": 1.0, "alpha": 2.0, "patience": 50})  # default params
study.optimize(objective, n_trials=N_TRIALS)


###################################################################################################
# We can show the optimization results as:


print(f"The number of trials: {len(study.trials)}")
print(f"Best value: {study.best_value} (params: {study.best_params})")
print(f"Number of evaluation: {num_evaluation} / {len(dataset) * N_TRIALS}")


###################################################################################################
# Visualize the optimization history.
# Note that this plot shows both completed and pruned trials in same ways.


optuna.visualization.plot_optimization_history(study)


###################################################################################################
# Visualize the number of evaluations in each trial.


x_values = [x for x in range(len(study.trials)) if x != study.best_trial.number]
y_values = [
    len(t.intermediate_values) for t in study.trials if t.number != study.best_trial.number
]
best_trial_y = [len(study.best_trial.intermediate_values)]
best_trial_x = [study.best_trial.number]
fig = go.Figure()
fig.add_trace(go.Bar(x=x_values, y=y_values, name="Evaluations"))
fig.add_trace(go.Bar(x=best_trial_x, y=best_trial_y, name="Best Trial", marker_color="red"))
fig.update_layout(
    title="Number of evaluations in each trial",
    xaxis_title="Trial number",
    yaxis_title="Number of evaluations before pruned",
)
fig


###################################################################################################
# Visualize the greedy solution (used by initial guess) of a TSP problem.


d = dataset[0]
result_idxs = tsp_greedy(d)
result_idxs = np.append(result_idxs, result_idxs[0])
fig = go.Figure()
fig.add_trace(go.Scatter(x=d[result_idxs, 0], y=d[result_idxs, 1], mode="lines+markers"))
fig.update_layout(
    title=f"greedy solution (initial guess),  cost: {tsp_cost(d, result_idxs):.3f}",
    xaxis=dict(scaleanchor="y", scaleratio=1),
)
fig


###################################################################################################
# Visualize the solution found by ``tsp_simulated_annealing`` of the same TSP problem.


params = study.best_params
options = SAOptions(
    max_iter=N_SA_ITER,
    patience=params["patience"],
    T0=params["T0"],
    alpha=params["alpha"],
)
result_idxs = tsp_simulated_annealing(d, options)
result_idxs = np.append(result_idxs, result_idxs[0])
fig = go.Figure()
fig.add_trace(go.Scatter(x=d[result_idxs, 0], y=d[result_idxs, 1], mode="lines+markers"))
fig.update_layout(
    title=f"n_iter: {options.max_iter}, cost: {tsp_cost(d, result_idxs):.3f}",
    xaxis=dict(scaleanchor="y", scaleratio=1),
)
fig

```
